{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "\n",
    "- [Probabilidad](#Probabilidad)\n",
    "    - [Operaciones con sucesos](#Operaciones-con-sucesos)\n",
    "    - [Probabilidad (definición)](#Probabilidad-(definición))\n",
    "    - [Propiedades de las probabilidades](#Propiedades-de-las-probabilidades)\n",
    "    - [Formula de Laplace](#Formula-de-Laplace)\n",
    "    - [Probabilidad condicional](#Probabilidad-condicional)\n",
    "    - [Teorema de la probabilidad total](#Teorema-de-la-probabilidad-total)\n",
    "\n",
    "\n",
    "- [Teorema de Bayes](#Teorema-de-Bayes)\n",
    "    - [El problema de Monty Hall](#El-problema-de-Monty-Hall)\n",
    "    - [Clasificador Naive Bayes](#Clasificador-Naive-Bayes)\n",
    "\n",
    "\n",
    "- [Variables Aleatorias](#Variables-Aleatorias)\n",
    "    - [Variables discretas](#Variables-discretas)\n",
    "        - [Función de probabilidad](#Función-de-probabilidad)\n",
    "        - [Función de Distribución](#Función-de-Distribución)\n",
    "        - [Valor esperado o esperanza](#Valor-esperado-o-esperanza)\n",
    "        - [Momento de orden m](#Momento-de-orden-m)\n",
    "        - [Varianza](#Varianza)\n",
    "    - [Variables aleatorias continuas](#Variables-aleatorias-continuas)\n",
    "        - [Esperanza y varianza para variables continuas](#Esperanza-y-varianza-para-variables-continuas)\n",
    "\n",
    "\n",
    "- [Distribuciones de Probabilidad](#Distribuciones-de-Probabilidad)\n",
    "    - [Distribuciones Discretas notables](#Distribuciones-Discretas-notables)\n",
    "        - [Distribución de Bernoulli](#Distribución-de-Bernoulli)\n",
    "        - [Distribución Binomial.](#Distribución-Binomial.)\n",
    "        - [Distribución Geométrica](#Distribución-Geométrica)\n",
    "        - [Distribución de Poisson](#Distribución-de-Poisson)\n",
    "        - [Distribución hipergeométrica](#Distribución-hipergeométrica)\n",
    "    - [Distribuciones continuas notables](#Distribuciones-continuas-notables)\n",
    "        - [Distribución uniforme](#Distribución-uniforme)\n",
    "        - [Distribución normal](#Distribución-normal)\n",
    "\n",
    "- [Más métricas](#Más-métricas)\n",
    "    - [Asimetría de una variable Aleatoria](#Asimetría-de-una-variable-Aleatoria)\n",
    "    - [Curtosis de una variable Aleatoria](#Curtosis-de-una-variable-Aleatoria)\n",
    "    - [Entropía de una variable aleatoria](#Entropía-de-una-variable-aleatoria)\n",
    "        \n",
    "- [Vectores Aleatorios](#Vectores-Aleatorios)\n",
    "    - [Vectores Aleatorios Bidimensionales](#Vectores-Aleatorios-Bidimensionales)\n",
    "        - [Función de distribución conjunta](#Función-de-distribución-conjunta)\n",
    "        - [Variable Aleatoria Bidimensional Discreta](#Variable-Aleatoria-Bidimensional-Discreta)\n",
    "            - [Marginales de una V.A.B.D.](#Marginales-de-una-V.A.B.D.)\n",
    "        - [Variable Aleatoria Continua Bidimensional](#Variable-Aleatoria-Continua-Bidimensional)\n",
    "            - [Distribución Gaussiana Bidimensional](#Distribución-Gaussiana-Bidimensional)\n",
    "        - [Valor esperado de Variables Aleatorias Bidimensionales](#Valor-esperado-de-Variables-Aleatorias-Bidimensionales)\n",
    "        - [Covarianza de Variables aleatorias Bidimensionales](#Covarianza-de-Variables-aleatorias-Bidimensionales)\n",
    "        - [Correlación entre Variables](#Correlación-entre-Variables)\n",
    " \n",
    " \n",
    "- [Ley de los grandes Números](#Ley-de-los-grandes-Números)\n",
    "\n",
    "                \n",
    "    \n",
    "- [Teorema central del límite](#Teorema-central-del-límite)\n",
    "       \n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad\n",
    "\n",
    "\n",
    "Para prepararnos en el estudio de la probabilidad empezaremos dando unas definiciones previas:\n",
    "\n",
    "\n",
    "- Experimento aleatorio:  Un experimento que bajo el mismo conjunto aparente de condiciones iniciales, puede presentar resultados diferentes, es decir, no se puede predecir o reproducir el resultado exacto de cada experiencia particular.\n",
    "\n",
    "\n",
    "- Suceso elemental: Es el resultado de realizar una sola vez el experimento aleatorio.\n",
    "\n",
    "- Espacio muestral: Es el conjunto de todos los sucesos elementales posibles en nuestro experimento aleatorio. denotado por $\\Omega$\n",
    "\n",
    "- Sucesos: denotamos por $P(\\Omega)$ al conjunto de todos los subconjuntos de $\\Omega$, a cada elemento de $P(\\Omega)$ lo llamamos suseso.\n",
    "\n",
    "\n",
    "Aquí cabe destacar el suceso seguro y el suceso imposible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones con sucesos\n",
    "\n",
    "- $\\Omega$\n",
    "- $\\emptyset$\n",
    "- $A \\cup B$ (A o b)\n",
    "- $A \\cap B$ (A y B)\n",
    "- $\\overline{A}$ que no pase A\n",
    "- $A - B = A \\cap \\overline{B}$ que pase A y no B\n",
    "- $\\overline{A} \\cap \\overline{B} = \\overline{(A \\cup B)}$ \n",
    "- $\\overline{A} \\cup \\overline{B} = \\overline{(A \\cap B)}$ \n",
    "\n",
    "\n",
    "Diremos que dos sucesos $A$ y $B$ son incompatibles si $A \\cap B = \\emptyset$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad (definición)\n",
    "\n",
    "Una probabilidad es un número entre 0 y 1 que mide la verosimilitud de que un evento pase. Puede estar justificada por:\n",
    "\n",
    "- Estimación personal\n",
    "- Estimación profesional\n",
    "- La frecuencia con la que se da\n",
    "- Cálculo formal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula de Laplace\n",
    "\n",
    "Si tenemos un experimento aleatorio en el que todos los sucesos elementales son igual de probables, entonces:\n",
    "\n",
    "\n",
    "$$P(A) = \\frac{\\textrm{número de casos favorables}}{\\textrm{número de casos posibles}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<h3>Propiedades de las probabilidades</h3>\n",
    "\n",
    "Las probabilidades, sean experimentales o teóricas, deben cumplir ciertas propiedades. La primera de ellas yes: _para un evento $A$ siempre se cumple que $P(A)$ es mayor igual que 0 y menor igual que 1_\n",
    "\n",
    "$$0 \\leq P(A) \\leq 1 $$\n",
    "\n",
    "Un evento con probabilidad 1 es uno que siempre ocurre, y un evento de probabilidad 0 es aquel que no llega a ocurrir nunca. La siguiente propiedad nos dice que la suma de las probabilidades de todos los posibles resultados de un experimento es exactamente igual a 1, si $A_1, A_2, \\cdots, A_n$ son todos los posibles resultados de un experimento se tiene:\n",
    "\n",
    "$$\\sum P(A_i) = P(A_1) + \\cdots + P(A_n) = 1$$\n",
    "\n",
    "\n",
    "<h4>Probabilidad del suceso imposible</h4>\n",
    "\n",
    "$$P(\\emptyset) = 0$$\n",
    "\n",
    "\n",
    "<h4>Probabilidad de que no pase A</h4>\n",
    "\n",
    "Para este caso definiremos al evento complementario de $A$ como el conjunto de todos los puntos del espacio muestra que no pertenecen al evento $A$, lo representaremos como $\\overline{A}$. Como sabemos que la suma de las probabilidades de todos los elementos del espacio muestra debe ser igual a 1, se tiene que $P(A) + P(\\overline{A}) = 1$, así para calcular el valor de $P(\\overline{A})$ haremos lo siguiente:\n",
    "\n",
    "$$P(\\overline{A}) = 1 - P(A)$$\n",
    "\n",
    "\n",
    "<h4>Probabilidad de A o B</h4>\n",
    "\n",
    "Para encontrar la probabilidad de que ocurra $A$ u ocurra $B$ usamos la _regla de la suma:_\n",
    "\n",
    "$$P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$$\n",
    "\n",
    "Gráficamente es más fácil ver que es lo que está ocurriendo con estas probabilidades, veamos un ejemplo con carros, si sacamos una llave al azar de un recipiente que contiene 66 llaves de las cuales 50 son de carros compactos y 38 son de carros extranjeros y queremos saber la probabilidad de que la llave que saquemos sea de _un carro compacto o uno extranjero_ tenemos que saber el número de casos favorables, como tenemos 50 carros compactos y 38 extranjeros, sin embargo si sumamos estas cantidades estaremos contando 2 veces a los 22 carros que son compactos y extranjeros, por lo que el número de casos favorables es de 66.\n",
    "\n",
    "<img src=\"Diagrama de Venn intercepción.png\" width = 500 height = 500>\n",
    "\n",
    "LLegado este punto definiremos los eventos **mutuamente excluyentes** que son aquellos eventos en los que la ocurrencia de uno excluye la ocurrencia del otro, es decir $P(A \\cap B) = 0$. Gráficamente estos son eventos dentro del espacio muestra que no se intersectan.\n",
    "\n",
    "<img src=\"Diagrama excluyentes.png\" width = 500 height = 500>\n",
    "\n",
    "\n",
    "\n",
    "$$P(A \\cup B) = P(A) + P(B)$$\n",
    "\n",
    "\n",
    "<h4>Probabilidad de que pase A y no B</h4>\n",
    "\n",
    "En este caso la probabilidad de $A - B$ será:\n",
    "\n",
    "$$P(A - B) = P(A) - P(A \\cap B)$$\n",
    "\n",
    "Esto es ya que A se puede descomponer como: $A = (A - B) \\cup (A \\cap B) $\n",
    "\n",
    "<img src=\"Diagrama de Venn intercepción.png\" width = 500 height = 500>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Probabilidad condicional</h3>\n",
    "\n",
    "Cuando hablamos de una probabilidad condicionada nos referimos a la probabilidad de que ocurra el evento $A$ teniendo información adicional, como por ejemplo que anteriormente se ha dado el evento $B$. Esta probabilidad la representamos como $P(A|B)$.\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Suponer que tenemos una clase con 20 hombres y 30 mujeres, de los cuales 15 hombres y 18 mujeres usan lentes:\n",
    "\n",
    "\n",
    "- ¿Cuál es la probabilidad de que un alumno use lentes?\n",
    "\n",
    "$$\\frac{33}{50}$$\n",
    "\n",
    "\n",
    "- ¿Cuál es la probabilidad de que un alumno sea mujer y use lentes?\n",
    "\n",
    "$$\\frac{18}{50}$$\n",
    "\n",
    "- ¿Cuál es la probabilidad de que una chica use lentes? (ya sabemos que es una chica)\n",
    "\n",
    "\n",
    "$$\\frac{\\frac{18}{50}}{\\frac{30}{50}} = \\frac{18}{30}$$\n",
    "\n",
    "\n",
    "- ¿Cuál es la probabilidad de que un alumno que lleva lentes, sea mujer?\n",
    "\n",
    "$$\\frac{\\frac{18}{50}}{\\frac{33}{50}} = \\frac{18}{33}$$\n",
    "\n",
    "\n",
    "\n",
    "La probabilidad condicionada cumple las siguientes propiedades:\n",
    "\n",
    "\n",
    "- $P(\\bar{B}|A) = 1 - P(B|A)$\n",
    "- $P(B_1 \\cup B_2|A) = P(B_1|A) + P(B_2|A) - P(B_1 \\cap B_2|A)$\n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Si el 15% de los adultos son hipertensos, un 25% de los adultos cree que son hipertensos y 9% de los adultos son hipertensos y cree que lo son:\n",
    "\n",
    "\n",
    "-¿Si un adulto cree que es hipertenso, cual es la probabilidad de que lo sea?\n",
    "\n",
    "$A$ - ser hipertenso\n",
    "$B$ - Creer ser hipertenso\n",
    "\n",
    "$P(A) = 0.15$\n",
    "$P(B) = 0.25$\n",
    "$P(A \\cap B) = 0.09$\n",
    "\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{0.09}{0.25} = 0.36$$\n",
    "\n",
    "\n",
    "$$P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{0.09}{0.15} = 0.6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "En 50% de los correos electronicos recibidos contienen archivos adjuntos, y el 65% de ellos son SPAM. Solo un 15% de los correos no tienen adjuntos y no son SPAM.\n",
    "\n",
    "- ¿Cuál es la probabilidad de que un correos lleve adjuntos si es SPAM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $A$ llevar adjuntos, $P(A) = 0.5$\n",
    "- $B$ ser SPAM, $P(B) = 0.65$\n",
    "- No tiener adjuntos y no ser SPAM → $\\overline{A} \\cap \\overline{B}$, $P(\\overline{A} \\cap \\overline{B}) = 0.15$\n",
    "\n",
    "Queremos saber $P(A|B)$ por lo que deberiamos aplicar la definición, pero nos falta $P(A \\cap B)$, sin empbargo noten que:\n",
    "\n",
    "$$P(\\overline{A} \\cap \\overline{B}) = P(\\overline{A \\cup B})$$\n",
    "$$P(A \\cup B) = 1 - P(\\overline{A \\cup B})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pA, pB, pnAynB = 0.5, 0.65, 0.15\n",
    "\n",
    "\n",
    "pAoB = 1 - pnAynB\n",
    "pAoB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usando la definición de $P(A \\cup B)$ podemos despejar $P(A \\cap B)$:\n",
    "\n",
    "$$P(A \\cap B) = P(A) + P(B) - P(A \\cup B)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pAyB = pA + pB - pAoB\n",
    "pAyB #cuidado con los errores de redondeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de probabilidad condicionada\n",
    "pA_si_B = pAyB / pB\n",
    "pA_si_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Teorema de la probabilidad total</h3>\n",
    "\n",
    "\n",
    "Suponga que tenemos dos sucesos A y B, entonces el teorema de la probabilidad total nos dice que:\n",
    "\n",
    "$$P(B) = P(B \\cap A) + P(B \\cap \\bar{A})$$\n",
    "$$P(B) = P(A) P(B|A) + P(\\bar{A}) P(B|\\bar{A})$$\n",
    "\n",
    "Supóngase que podemos dividir el espacio muestra en $A_n$ eventos mutuamente excluyentes, y que se quiere conocer la probabilidad de que ocurra un evento $B$.\n",
    "\n",
    "\n",
    "<img src=\"teorema de la probabilidad total.jpg\" width = 500 height = 500>\n",
    "\n",
    "\n",
    "En la imagen podemos ver que $B = (B \\cap A_1) \\cup (B \\cap A_2) \\cup \\cdots (B \\cap A_n)$. Como los eventos son mutuamente excluyentes se tiene que:\n",
    "\n",
    "$$P(B) = P(B \\cap A_1) + P(B \\cap A_2) + \\cdots + P(B \\cap A_n)$$\n",
    "\n",
    "Reescribiendo $P(B)$ usando la definición de la probabilidad $P(B \\cap A_i)$ tenemos _el teorema de la probabilidad total:_\n",
    "\n",
    "$$ P(B) = P(B|A_1)P(A_1) + P(B|A_2)P(A_2) + \\cdots + P(B|A_n)P(A_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema de diagnóstico**\n",
    "\n",
    "Una de las aplicaciones de la probabilidad es la realización de algoritmos de clasificación, y para ejemplificar esto vamos a imaginar una prueba diagnostico (como las que utilizan para el COVID-19), en un caso como este hay dos posibles eventos, el primero es _tener la enfermedad_ ($E$) y el segundo es _dar positivo en la prueba,_ ($T$) vamos a ver en la siguiente tabla (matriz de confusión) que es lo que está ocurriendo:\n",
    "\n",
    "\n",
    "|Realidad/Resultado|Test Positivo|Test Negativo|\n",
    "|:----------------:|:-----------:|:-----------:|\n",
    "|Enermo|Correcto|Error|\n",
    "|No enfermo|Error|Correcto|\n",
    "\n",
    "- Si la persona está enferma y el test da positivo, entonces tenemos un verdadero positivo (**VP**).\n",
    "- Si la persona está enferma pero el test da negativo estamos ante un falso negativo (**FN**).\n",
    "- Si la persona no está enferma y el test da positivo, entonces tenemos un falso positivo (**FP**).\n",
    "- Si la persona no está enferma y el test da negativo tenemos un verdadero negativo (**VN**).\n",
    "\n",
    "¿Qué es peor, un falso negativo o un falso positivo? Con los eventos que definimos antes podemos calcular los falsos positivos y negativos fácilmente:\n",
    "\n",
    "- **FN** → $E \\cap \\overline{P}$\n",
    "- **FP** → $\\overline{E} \\cap P$\n",
    "\n",
    "Vamosa definir entonces lo siguiente:\n",
    "\n",
    "- Coeficiente de **FP** → $P(T|\\overline{E})$\n",
    "- Coeficiente de **FN** → $P(\\overline{T}|E)$\n",
    "\n",
    "Siempre se va a tratar que estas dos cantidades sean muy bajas (en la practica es imposible que sean 0), veamos un ejemplo:\n",
    "\n",
    "\n",
    "_Imaginemos que una prueba de COVID-19 de anticuerpos se hiciera a 1000 trabajadores sanitarios (en un contexto de alto riesgo) que habían tenido síntomas:_\n",
    "\n",
    "- _464 personas darían positivo en la prueba de covid-19. De estas, siete personas (2%) no tendrían covid-19 (resultado falso positivo)._\n",
    "\n",
    "- _537 personas darían negativo en la prueba de covid-19. De estas, 43 personas (8%) tendrían realmente covid-19 (resultado falso negativo)._\n",
    "\n",
    "_¿Cuál es la probabilidad de que una persona elegida al azar este enferma ($P(E)$)?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 464/1000\n",
    "FP, FN = 0.02, 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(T) = P(E)P(T|E) + P(\\overline{E})P(T|\\overline{E})$$\n",
    "$$P(T) = P(E)(1 - P(\\overline{T}|E)) + (1 - P(E))P(T|\\overline{E})$$\n",
    "$$P(E) = \\frac{P(T) - P(T|\\overline{E})}{((1 - P(\\overline{T}|E)) - P(T|\\overline{E}))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = (T - FP)/((1 - FN) - FP)\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos fueron tomados de un estudio real y 500 (50%) de ellos realmente tenían covid-19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema de Bayes\n",
    "\n",
    "\n",
    "El teorema de Bayes proporciona una forma alternativa para calcular una probabilidad condicional.\n",
    "\n",
    "Es un cálculo engañosamente simple, aunque se puede usar para calcular fácilmente la probabilidad condicional de eventos donde la intuición a menudo falla.\n",
    "\n",
    "Aunque es una herramienta poderosa en el campo de la probabilidad, el Teorema de Bayes también se usa ampliamente en el campo del aprendizaje automático. \n",
    "\n",
    "$$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
    "\n",
    "\n",
    "En algunas ocasiones el denominador del teorema de Bayes no será posible de obtener de forma directa, por lo que nos podremos ayudar del teorema de la probabilidad total.\n",
    "\n",
    "$$P(A|B) = \\frac{P(A)P(B|A)}{P(A)P(B|A) + P(\\bar{A})P(B|\\bar{A})}$$\n",
    "\n",
    "\n",
    "y tenemos que:\n",
    "\n",
    "- $A$ es entendido como una hipótesis contrastable, por experiencia o análisis de datos previos. por lo que $P(A)$ se llama _probabilidad previa_ o _a priori_ de que la hipótesis $A$ sea cierta.\n",
    "\n",
    "\n",
    "- $B$ se introduce como condición con el objetivo de aportar algo nuevo a la probabilidad del evento $A$. $B$ es otro evento que analizamos por separado, con sus propios datos que nos permitan conocer su probabilidad, por lo tanto $P(B)$ es la probabilidad de observar $B$ independientemente de que la hipótesis $A$ sea cierta o no, se suele llamar _evidencia_.\n",
    "\n",
    "- $P(B|A)$ es conocido como _verosimilitud_ o _fiabilidad_. Es decir, la probabilidad de haber observado el evento $B$ sabiendo que $A$ es cierta.\n",
    "\n",
    "- $P(A|B)$ es la probabilidad de que la hipótesis $A$ sea cierta una vez observados los datos. Recibe el nombre de probabilidad _a posteriori_ y es aquella que deseamos calcular. Es una probabilidad actualizada de que observemos $A$.\n",
    "\n",
    "\n",
    "Ahora veamos un ejemplo del teorema de Bayes. Un ejemplo excelente y ampliamente utilizado del beneficio del Teorema de Bayes es el análisis de una prueba de diagnóstico médico. Retomemos el ejemplo de la prueba anterior, los datos del ejemplo anterior son validos cuando la prueba es aplicada al personal médico que tiene alto riesgo de ser infectado, pero cuando la prueba es aplicada a la población en general presenta un valor de **FP** de 1.26% y un valor de **FN** de 8%.\n",
    "\n",
    "Problema: si un paciente seleccionado al azar se hace la prueba y resulta positivo, ¿cuál es la probabilidad de que el paciente tenga COVID-19?\n",
    "\n",
    "\n",
    "En este caso, la prueba tiene una sensibilidad del 92%. Es decir, de todas las personas que tienen COVID-19 y se hacen pruebas, el 92% de ellas obtendrá un resultado positivo de la prueba.\n",
    "\n",
    "$$P(T|E) = 0.92$$\n",
    "\n",
    "\n",
    "Dada esta información, nuestra intuición sugeriría que hay un 92% de probabilidad de que el paciente tenga COVID-19. Pero nuestra intuición suele fallar. Este tipo de error en la interpretación de las probabilidades es tan común que tiene su propio nombre; se le conoce como la falacia de la tasa base.\n",
    "\n",
    "Tiene este nombre porque el error al estimar la probabilidad de un evento es causado por ignorar la tasa base. Es decir, ignora la probabilidad de que una persona seleccionada al azar tenga COVID-19, independientemente de los resultados de una prueba de diagnóstico. Teniendo en cuenta el número de infectados y la población de México al 27 de Enero de 2021, la probabilidad de que un mexicano tenga COVID-19 es del 1.4%.\n",
    "\n",
    "\n",
    "$$P(E) = 0.014$$\n",
    "\n",
    "\n",
    "\n",
    "Podemos calcular correctamente la probabilidad de que un paciente tenga COVID-19 con un resultado positivo en la prueba usando el Teorema de Bayes.\n",
    "\n",
    "\n",
    "$$P(E|T) = \\frac{P(E)P(T|E)}{P(T)}$$\n",
    "\n",
    "\n",
    "En este caso $P(T)$ no está dada directamente, por lo que nos apoyaremos del teorema de la probabilidad total:\n",
    "\n",
    "\n",
    "$$P(T) = P(E)P(T|E) + P(\\overline{E})P(T|\\overline{E})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_theorem(p_a, p_b_given_a, p_b_given_not_a):\n",
    "\n",
    "    not_a = 1 - p_a\n",
    "    p_b = p_b_given_a * p_a + p_b_given_not_a * not_a\n",
    "    p_a_given_b = (p_b_given_a * p_a) / p_b\n",
    "    \n",
    "    return p_a_given_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidad de estar enfermo\n",
    "p_a = 0.014\n",
    "# P(T|E) sensibilidad (1 - P(not T|E))\n",
    "p_b_given_a = 0.92\n",
    "# P(B|not A)\n",
    "p_b_given_not_a = 0.0126\n",
    "\n",
    "bayes_theorem(p_a, p_b_given_a, p_b_given_not_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El cálculo sugiere que, si una persona al azar (presente sintomas o no) se va a hacer la prueba del COVID-19 y resulta positivo, tiene un 50% de probablidades de tener la enfermedad, y es por esto que se recomienda que te hagas la prueba solo sí tienes sintomas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidad de estar enfermo\n",
    "p_a = 0.50\n",
    "# P(T|E) sensibilidad (1 - P(not T|E))\n",
    "p_b_given_a = 0.92\n",
    "# P(B|not A)\n",
    "p_b_given_not_a = 0.02\n",
    "\n",
    "bayes_theorem(p_a, p_b_given_a, p_b_given_not_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los calculos ralizados pero tomando los datos de los trabajadores del sector salud, que tenian un 50% de probabilidades de estar enfermos, y en este caso si se hacen la prueba y el resultado es positivo la probabilidad de estar enfermos es mucho más alta (97.9%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de Monty Hall\n",
    "\n",
    "\n",
    "El concursante debe elegir una puerta entre tres (todas cerradas); el premio consiste en llevarse lo que se encuentra detrás de la elegida. Se sabe con certeza que tras una de ellas se oculta un automóvil, y tras las otras dos hay cabras. Una vez que el concursante haya elegido una puerta y comunicado su elección a los presentes, el presentador, que sabe lo que hay detrás de cada puerta, abrirá una de las otras dos en la que haya una cabra. A continuación, le da la opción al concursante de cambiar de puerta si lo desea (tiene dos opciones). ¿Debe el concursante mantener su elección original o escoger la otra puerta? ¿Hay alguna diferencia?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Ejercicio__\n",
    "\n",
    "Simular el juego en 1000 ocasiones en las que si se cambia de puerta, y 1000 en las que no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Puerta:\n",
    "    \n",
    "    def __init__(self, cabra = False):\n",
    "        self.cabra = cabra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puerta1 = Puerta()\n",
    "puerta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puerta1.cabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "puertas = [Puerta(), Puerta(True), Puerta(True)]\n",
    "random.shuffle(puertas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "victorias = 0\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    #se generan las puertas\n",
    "    puertas = [Puerta(), Puerta(True), Puerta(True)]\n",
    "    random.shuffle(puertas)\n",
    "    \n",
    "    #el jugador elige una puerta al azar\n",
    "    elec = puertas.pop()\n",
    "    \n",
    "    #el presentador abre (descarta) una puerta con cabra\n",
    "    for p in puertas:\n",
    "        \n",
    "        if p.cabra:\n",
    "            puertas.remove(p)\n",
    "            break\n",
    "    \n",
    "    #el jugador cambia de puerta:\n",
    "    elec = puertas.pop()\n",
    "    \n",
    "    #contar victorias\n",
    "    if not elec.cabra:\n",
    "        victorias += 1\n",
    "    \n",
    "victorias / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "victorias = 0\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    #se generan las puertas\n",
    "    puertas = [Puerta(), Puerta(True), Puerta(True)]\n",
    "    random.shuffle(puertas)\n",
    "    \n",
    "    #el jugador elige una puerta al azar\n",
    "    elec = puertas.pop()\n",
    "    \n",
    "    #el presentador abre (descarta) una puerta con cabra\n",
    "    for p in puertas:\n",
    "        \n",
    "        if p.cabra:\n",
    "            puertas.remove(p)\n",
    "            break\n",
    "    \n",
    "    #el jugador no cambia de puerta:\n",
    "    #elec = puertas.pop()\n",
    "    \n",
    "    #contar victorias\n",
    "    if not elec.cabra:\n",
    "        victorias += 1\n",
    "    \n",
    "victorias / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La intuición nos puede traicionar, y pensar que da igual, que al quedar dos puertas la elección es un 50|50. pero es incorrecto, la mejor opción siempre es cambiar. veamos esto, suponga que $G$ es el evento _ganar_ y los eventos _elegir la puerta con el auto_ y _elegir la puerta con la cabra_ son respectivamente $A$ y $C$ entonces:\n",
    "\n",
    "$$P(G) = P(G \\cap A) + P(G \\cap C)$$\n",
    "$$P(G) = P(A)P(G|A) + P(C)P(G|C)$$\n",
    "\n",
    "Resulta claro que $P(A) = \\frac{1}{3}$ y $P(C) = \\frac{2}{3}$, ahora pensemos que no se cambia de puerta, en este caso $P(G|A) = 1$ y $P(G|C) = 0$. Pero si cambiamos de puerta las probabilidades se invierten, $P(G|A) = 0$ y $P(G|C) = 1$.\n",
    "\n",
    "\n",
    "Es decir si no cambiamos de puerta $P(G) = \\frac{1}{3}$, pero si cambiamos de puerta $P(G) = \\frac{2}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Naive Bayes\n",
    "\n",
    "\n",
    "El teorema de Bayes supone que cada variable de entrada depende de todas las demás variables. Esta es una causa de complejidad en el cálculo. Podemos eliminar esta suposición y considerar que cada variable de entrada es independiente entre sí.\n",
    "\n",
    "Esto cambia el modelo de un modelo de probabilidad condicional dependiente a un modelo de probabilidad condicional independiente y simplifica drásticamente el cálculo. Supongamos que estamos observando dos características de un objeto $X_1$, y $X_2$, podemos usar el teorema de Bayes para saber cuál es la probabilidad de que el objeto pertenezca a una determinada clase $C$.\n",
    "\n",
    "$$P(C|X_1) = \\frac{P(C)P(X_1|C)}{P(X_1)}$$\n",
    "\n",
    "Podemos hacer algo similar para $X_2$, ahora podemos querer mejorar esta probabilidad haciendo que se cumplan las dos condiciones a la vez, es decir:\n",
    "\n",
    "\n",
    "$$P(C|X_1 \\cap X_2) = \\frac{P(C)P(X_1 \\cap X_2|C)}{P(X_1 \\cap X_2)}$$\n",
    "\n",
    "\n",
    "Noten que en principio se cumple que:\n",
    "\n",
    "$$P(X_1 \\cap X_2) = P(X_1)P(X_2|X_1)$$\n",
    "\n",
    "El modelo de Naive Bayes va a suponer que estos eventos son independientes y por ende:\n",
    "\n",
    "$$P(X_1 \\cap X_2) = P(X_1)P(X_2)$$\n",
    "\n",
    "\n",
    "lo que convierte a nuestra expresión en lo siguiente:\n",
    "\n",
    "\n",
    "$$P(C|X_1 \\cap X_2) = \\frac{P(C)P(X_1|C)P(X_2|C)}{P(X_1)P(X_2)}$$\n",
    "\n",
    "\n",
    "Naive Bayes es un algoritmo de clasificación para problemas de clasificación binaria (dos clases) y multiclase. Se llama Naive Bayes (Bayes ingenuo) o Bayes idiota porque los cálculos de las probabilidades para cada clase se simplifican para que sus cálculos sean manejables.\n",
    "\n",
    "En lugar de intentar calcular las probabilidades de cada valor de atributo, se supone que son condicionalmente independientes dado el valor de la clase.\n",
    "\n",
    "Ahora si tenemos un conjunto de $n$ características y $m$ clases podemos extender esta definición para cada clase, llamemos $Y$ al conjunto de todas las características y obtendremos lo siguiente:\n",
    "\n",
    "$$y = argmax_Y \\frac{P(C)P(X_1|C)P(X_2|C) \\cdots P(X_n|C)}{P(X_1)P(X_2) \\cdots P(X_n)}$$\n",
    "\n",
    "\n",
    "Podemos ser aún más idiotas y pensar que como las $P(X_i)$ no cambian, las podemos ignorar y obtener el siguiente resultado:\n",
    "\n",
    "\n",
    "$$y = argmax_Y P(C)P(X_1|C)P(X_2|C) \\cdots P(X_n|C)$$\n",
    "\n",
    "Esta es una suposición muy fuerte que es muy poco probable en datos reales, es decir, que los atributos no interactúan. Sin embargo, el enfoque funciona sorprendentemente bien en datos donde esta suposición no se cumple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(url, names=['lng sepalo','anch sepalo','lng petalo','anch petalo','especie'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset se usa como datos de entrenamiento para un modelo de machine learning cuyo objetivo es determinar de forma automática la especie a la que pertenece una determinada flor, a partir de las medidas 4 atributos o características. En particular, la longitud y la anchura de sus pétalos y sépalos expresadas en centímetros. Por tanto, se trata de un problema de 4 dimensiones, en el que la variable objetivo (target) es la especie. Los datos se pueden representar en forma de una matriz de 150 filas (los datos de cada flor), por 4 columnas (las medidas de sus pétalos/sépalos). La quinta, corresponde a la variable objetivo, la especie.\n",
    "\n",
    "\n",
    "<img src=\"Iris data set.PNG\" width = 600 height = 600> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "shuffle_data = shuffle(df)\n",
    "shuffle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento = shuffle_data.iloc[:int(df.shape[0] * 0.8)]\n",
    "entrenamiento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = shuffle_data.iloc[int(df.shape[0] * 0.8):]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['especie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    \n",
    "    \n",
    "    #alimentar el modelo\n",
    "    def fit(self, x, tarjet):\n",
    "        \n",
    "        num_data, num_features = x.shape\n",
    "        #unimos los datos y el tarjet\n",
    "        x['class'] = tarjet\n",
    "        self.clases = np.unique(tarjet)#identifico las clases\n",
    "        \n",
    "        data_clases = {k : x[x['class'] == k] for k in self.clases} #filtro mis clases\n",
    "        \n",
    "        self._data_means  = {k : data_clases[k].mean().values for k in self.clases} #array con las medias\n",
    "        self._data_std    = {k : data_clases[k].std().values for k in self.clases} #array con las desviaciones estandar\n",
    "        self._prioris     = {k : data_clases[k].shape[0] / num_data for k in self.clases} #probabilidades a priori\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        l = x.shape[0]\n",
    "        \n",
    "        pred = [self._predict(x.iloc[i]) for i in range(l)]\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "        \n",
    "    def _predict(self, x):\n",
    "        \n",
    "        post = []\n",
    "        \n",
    "        for cl in self.clases:\n",
    "            \n",
    "            #elementos de la clase\n",
    "            mean = self._data_means[cl]\n",
    "            std  = self._data_std[cl]\n",
    "            pri = self._prioris[cl]\n",
    "            \n",
    "            \n",
    "            condi = np.array([stats.norm(mean[i], std[i]).pdf(x[i]) for i in range(len(mean))]) #verosimilitudes\n",
    "            pt  = pri * condi.prod()\n",
    "            post.append(pt)\n",
    "            \n",
    "        return self.clases[np.argmax(post)] #argmax devuelve el indice del maximo de la lista\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = entrenamiento.iloc[:,:-1], entrenamiento.iloc[:, -1] #separar variables y el tarjet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Naive_Bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prueba = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prueba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_prueba)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['especie'] == pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test['especie'] == pred).sum() / test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Aleatorias\n",
    "\n",
    "\n",
    "Una variable aleatoria es una función que asigna un valor, usualmente numérico, al resultado de un experimento aleatorio. Una variable aleatoria puede concebirse como un valor numérico que está afectado por el azar. Dada una variable aleatoria no es posible conocer con certeza el valor que tomará esta al ser medida o determinada, aunque sí se conoce que existe una distribución de probabilidad asociada al conjunto de valores posibles. Por ejemplo, durante la actual pandemia, se sabe que una persona cualquiera puede enfermar o no (suceso), pero no se sabe cuál de los dos sucesos va a ocurrir. Solamente se puede decir que existe una probabilidad de que la persona enferme. En general hay dos tipos de variables aleatorias, las continuas y las discretas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variables discretas\n",
    "#### Función de probabilidad\n",
    "\n",
    "\n",
    "En teoría de la probabilidad, una función de probabilidad (también denominada función de masa de probabilidad o función densidad de probabilidad: __PDF__) es una función que asocia a cada punto de su espacio muestral X la probabilidad de que esta lo asuma. Suponga que nuestra variable aleatoria es $X$ y esta puede asumir $k$ valores diferentes $x_1, x_2, \\cdots, x_k$, entonces la función de probabilidad asociada es:\n",
    "\n",
    "$$P_X(x_i) = P(X = x_i)$$\n",
    "\n",
    "\n",
    "Esta función cumple siempre que:\n",
    "\n",
    "- $0 \\leq P_X(x) \\leq 1$\n",
    "- $\\sum P_X(x_i) = 1$\n",
    "\n",
    "\n",
    "\n",
    "Imaginemos que estamos realizando un experimento que consiste en lanzar una moneda 3 veces al aire y en medir cuantas veces la moneda cae cara, en este caso nuestra variable aleatoria $X$ tomada los valores 0, 1, 2, 3 y el espacio muestra del experimento será:\n",
    "\n",
    "$$\\Omega = \\{ ccc, cc+, c+c, +cc, c++, +c+, ++c, +++ \\}$$\n",
    "\n",
    "\n",
    "En este experimento nuestra función de probabilidad seria:\n",
    "\n",
    "\n",
    "- $P(X = 0) = \\frac{1}{8}$\n",
    "- $P(X = 1) = \\frac{3}{8}$\n",
    "- $P(X = 2) = \\frac{3}{8}$\n",
    "- $P(X = 3) = \\frac{1}{8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de Distribución\n",
    "\n",
    "La función de distribución o función de probabilidad acumulada, se representa por $F_X(x)$ y nos representa la probabilidad de que la variable aleatoria $X$ tome un valor igual o menor a $x$, es decir:\n",
    "\n",
    "\n",
    "$$F_X(x) = P(X \\leq x)$$\n",
    "\n",
    "\n",
    "Note las siguientes propiedades:\n",
    "\n",
    "- $P(X > x) ) = 1 - P(X \\leq x) = 1 - F_X(x)$\n",
    "- si se tienen $a$ y $b$ tales que $ a < b$ entonces: $P(a < X \\leq b) = P(X \\leq b) - P(X \\leq a) = F_X(b) - F_X(a)$\n",
    "\n",
    "\n",
    "Note que esta función es siempre creciente, vale 0 en menos infinito y vale 1 en infinito. En el caso de que $X$ sea una variable aleatoria discreta entonces la función de distribución será:\n",
    "\n",
    "$$F_X(x_i) = \\sum_{x \\leq x_i} P_X(X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valor esperado o esperanza\n",
    "\n",
    "Vamos a definir el valor esperado de una variable aleatoria discreta $X$ como:\n",
    "\n",
    "\n",
    "$$E(X) = \\sum xP_X(x)$$\n",
    "\n",
    "\n",
    "También se le conoce como media y se puede representar frecuentemente como $\\mu$. tomen en cuenta que nosotros podemos transformar la variable aleatoria usando una función $g(X)$, en ese caso el valor esperado de dicha función será:\n",
    "\n",
    "$$E(g(X)) = \\sum g(x)P_X(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**\n",
    "\n",
    "¿Cuándo un juego es justo?, pues cuando la ganancia esperada (valor esperado) de todos los jugadores es 0. Imaginemos que tenemos dos jugadores $A$ y $B$, van a tirar un dado por turnos y va a ganar el primero que obtenga un 5, cada uno va a apostar una cantidad $C_A$ y $C_B$ y el ganador se lleva ambas cantidades. Suponiendo que primero va a lanzar A, ¿qué condición deben cumplir las cantidades para que este juego sea justo?\n",
    "\n",
    "\n",
    "Vamos a definir el evento $A_i$ como _el jugador A gana en la tirada i_ y el evento $B_i$ _el jugador B gana en la tirada i_. Veamos la probabilidad de que gane cada jugador.\n",
    "\n",
    "$$P(A) = \\sum_{i = 1}^{\\infty} P(A_{2i - 1})$$\n",
    "$$P(B) = \\sum_{i = 1}^{\\infty} P(B_{2i})$$\n",
    "\n",
    "\n",
    "Ahora la probabilidad de que $A$ gane en la primera tirada es $\\frac{1}{6}$, de que gane en la tercera es $P(A_3) = (\\frac{5}{6})^2 \\frac{1}{6}$ ya que tiene que perder en la primera y $B$ en la segunda, entonces:\n",
    "\n",
    "$$P(A_{2i-1}) =  (\\frac{5}{6})^{2i-2} \\frac{1}{6}$$\n",
    "$$P(A) = \\sum_{i=1}^{\\infty} (\\frac{5}{6})^{2i-2} \\frac{1}{6} = (\\frac{5}{6})^{-2} \\frac{1}{6}\\sum_{i=1}^{\\infty}(\\frac{5}{6})^{2i} = \\frac{6}{25}\\sum_{i=1}^{\\infty}(\\frac{25}{36})^{i}$$\n",
    "\n",
    "$$P(A) =  \\frac{6}{25} \\frac{\\frac{25}{36}}{1 - \\frac{25}{36}} = \\frac{6}{25} \\frac{\\frac{25}{36}}{\\frac{11}{36}} = \\frac{6}{11}$$\n",
    "\n",
    "En el caso de $B$ se tiene que $P(B_2) = (\\frac{5}{6})\\frac{1}{6}$, $P(B_4) = (\\frac{5}{6})^3 \\frac{1}{6}$ y en general:\n",
    "\n",
    "$$P(B_{2i}) = (\\frac{5}{6})^{2i - 1}\\frac{1}{6}$$\n",
    "\n",
    "$$P(B_{2i}) = \\sum_{i=1}^{\\infty}(\\frac{5}{6})^{2i - 1}\\frac{1}{6} = (\\frac{5}{6})^{-1} \\frac{1}{6}\\sum_{i=1}^{\\infty}(\\frac{25}{36})^{i} = \\frac{1}{5} \\frac{\\frac{25}{36}}{ 1 - \\frac{25}{36}} = \\frac{1}{5} \\frac{\\frac{25}{36}}{\\frac{11}{36}} = \\frac{5}{11}$$\n",
    "\n",
    "\n",
    "\n",
    "Ahora que ya sabemos las probabilidades de que cada uno gane, sea $X$ la variable aleatoria que nos indica que es lo que gana el jugador $A$, notemos que:\n",
    "\n",
    "$$X(\\Omega) = \\{ C_B, -C_A \\}$$\n",
    "\n",
    "Y también tenemos que:\n",
    "\n",
    "- $P(X = C_B) = P(A) = \\frac{6}{11}$\n",
    "- $P(X = - C_A) = P(B) = \\frac{5}{11}$\n",
    "\n",
    "Cálculamos el valor esperado e igualamos a 0:\n",
    "\n",
    "$$E[X] = C_B P(A) - C_A P(B) = C_B \\frac{6}{11} - C_A \\frac{5}{11} = 0$$\n",
    "$$C_B \\frac{6}{11} = C_A \\frac{5}{11}$$\n",
    "$$C_B = \\frac{5}{6} C_A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momento de orden m\n",
    "\n",
    "Llamaremos momento de orden $m$ en el punto $C$ a:\n",
    "\n",
    "$$E((X - C)^m)$$\n",
    "\n",
    "Si $C = 0$ y $m = 1$ obtenemos el valor esperado. Los momentos en los que $C = 0$ reciben el nombre de momentos respecto al origen y cuando $C = E[X]$ se denominan momento central."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varianza\n",
    "\n",
    "Si $X$ es una variable aleatoria llamaremos varianza de $X$ a:\n",
    "\n",
    "$$var(x) = E((X - E(x))^2)$$\n",
    "\n",
    "Es decir la varianza es el momento central de orden dos y se cumple que su raiz cuadrada es $\\sigma$ la desviación estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformaciones lineales de Variables Aleatorias\n",
    "\n",
    "Si tenemos una variable aleatoria $X$, una transformación lineal de X es otra v.a. $Y = b + aX$ donde $a, b \\in \\mathbb{R}$. y si $E[X] = \\mu_X$ y $var(X) = \\sigma^{2}_{X}$, entonces:\n",
    "\n",
    "- $E[Y] = E[b +aX] = b + a\\mu_x$\n",
    "- $var(Y) = var(b +aX) = a^2 \\sigma^{2}_{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables aleatorias continuas\n",
    "\n",
    "\n",
    "Son las variables que toman valores en un intervalo y cumplen principalmente que $P(X = x_0) = 0$, por lo que a diferencia de las variables discretas, aquí pierde el sentido hablar de una función de probabilidad. Para las variables continuas vamos a definir la función de densidad $f_X(x)$ que va a cumplir las siguientes propiedades:\n",
    "\n",
    "\n",
    "- $f_X(x) \\geq 0$\n",
    "- Debe ser continua en excepto en una cantidad finita de puntos.\n",
    "- $\\int_{-\\infty}^{\\infty} f_X(x) = 1$\n",
    "\n",
    "\n",
    "Sea $X$ una variable aleatoria continua, entonces a función de distribución $F_X(x)$ para la variable $X$ será:\n",
    "\n",
    "$$F_X(x) = \\int_{-\\infty}^{x} f_X(t)dt$$\n",
    "\n",
    "\n",
    "Esto implica que si queremos conocer $P(a < X < b)$ esto es:\n",
    "\n",
    "$$P(a < X < b) = \\int_{a}^{b} f_X(t)dt$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esperanza y varianza para variables continuas\n",
    "\n",
    "\n",
    "Las definiciones serán similares al caso continuo. La esperanza de una variable aleatoria continua $X$ será:\n",
    "\n",
    "\n",
    "$$E(X) = \\int_{-\\infty}^{\\infty} xf_X(x)dx$$\n",
    "\n",
    "\n",
    "En el caso de la varianza se tiene:\n",
    "\n",
    "\n",
    "$$var(X) = E((X - \\mu)^2) =\\int_{-\\infty}^{\\infty}(x - \\mu)^2f_X(x)dx$$\n",
    "\n",
    "$$var(X) = E(X^2) - \\mu_{X}^{2} = \\int_{-\\infty}^{\\infty} x^2 f_X(x)dx - \\mu_{X}^{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**\n",
    "\n",
    "Supongamos que se tiene una v.a. $X$ con función de densidad: \n",
    "\n",
    "$$\n",
    "f_X(x)\n",
    "=\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "2(1-x)&\\text{si}&0<x<1\\\\\n",
    "0&\\text{ }&\\text{en otro caso}\\\\\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "Para comprobar que es una v.a. hayq ue verificar que sea continua salvo un conjunto finito de puntos (en este caso en 0 y 1) y que integre a 1:\n",
    "\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} f_X(x) = 2\\int_{0}^{1} (1 - x)dx =\\left. \\left [2x - x^2 \\right ] \\right |_{0}^{1} = [1 - 0] = 1$$\n",
    "\n",
    "Ahora vamos a calcular su esperanza:\n",
    "\n",
    "$$E[X] = \\int_{0}^{1} xf(x)dx = 2\\int_{0}^{1}x(1-x)dx = 2\\int_{0}^{1} x - x^2 dx = \\left. \\left [x^2 - \\frac{2}{3}x^2 \\right ] \\right |_{0}^{1} = [1 - \\frac{2}{3}] = \\frac{1}{3}$$\n",
    "\n",
    "\n",
    "Ahora calculemos la varianza, para ello necesitamos primero el valor esperado de $X^2$:\n",
    "\n",
    "$$E[X^2] = 2\\int_{0}^{1} x^2(1-x)dx = 2\\int_{0}^{1} x^2 - x^3 dx = \\left. \\left [\\frac{2}{3} x^3 - \\frac{1}{2}x^4 \\right ] \\right |_{0}^{1} = \\frac{1}{6}$$\n",
    "\n",
    "Y finalmente la varianza de $X$ es:\n",
    "\n",
    "$$var(X) = E[X^2] - E[X]^2 = \\frac{1}{6} - \\frac{1}{9} = \\frac{1}{18}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones de Probabilidad\n",
    "### Distribuciones Discretas notables\n",
    "\n",
    "\n",
    "Una vez que definimos las propiedades anteriores es hora de hablar de las distribuciones de probabilidad notables de cada tipo de variable y de empezar a trabajarlas con python, empezaremos como es natural con las variables discretas.\n",
    "\n",
    "\n",
    "#### Distribución de Bernoulli\n",
    "\n",
    "\n",
    "\n",
    "Esta es la distribución más sencilla de todas, en la que tenemos un experimento que solo tiene dos posibles resultados, éxito o fracaso, y vamos a suponer que la probabilidad de éxito $P(E) = p$ y la probabilidad de fracaso es $P(F) = 1 - p = q$, la variable aleatoria que describe este suceso es $X$ talque $X(E) = 1$ y $X(F) = 0$. Bajo estas características diremos que $X$ sigue una distribución de Bernoulli con parámetro $p$, y lo denotaremos como:\n",
    "\n",
    "$$X \\sim Ber(p)$$\n",
    "\n",
    "\n",
    "A este tipo de experimento se le conoce como experimento de Bernoulli (Jacob), En este caso el valor esperado es simplemente $E(X) = p$ y la varianza es $var(X) = pq$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución Binomial.\n",
    "\n",
    "la distribución binomial es una distribución de probabilidad discreta que cuenta el número de éxitos en una secuencia de $n$ ensayos de [Bernoulli](https://es.wikipedia.org/wiki/Ensayo_de_Bernoulli) **independientes entre sí**. En la distribución binomial el anterior experimento se repite $n$ veces, de forma independiente, y se trata de calcular la probabilidad de un determinado número de éxitos. La representaremos como:\n",
    "\n",
    "\n",
    "$$X \\sim B(n, p)$$\n",
    "\n",
    "\n",
    "\n",
    "La variable aleatoria que analizamos es el número de casos _éxito_ dentro de los n ensayos, por lo que la variable $X$ toma valores en ${0, 1, 2, 3, \\cdots, n}$. La función de probabilidad de la distribución binomial es:\n",
    "\n",
    "$$P(x) = {n \\choose x}p^x(1-p)^{n-x}$$\n",
    "\n",
    "Recordando que ${n \\choose x} = \\frac{n!}{x!(n-x)!}$\n",
    "\n",
    "\n",
    "Y la función de distribución será:\n",
    "\n",
    "$$F_X(x) = \\sum_{i = 0}^{x} P(X = i)$$\n",
    "\n",
    "\n",
    "Y se tiene $E(X) = np$ y la varianza es $var(X) = npq$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats import binom #función de probabilidad pfm y la de distribución cdf, \n",
    "# si quieres una muestra aleatorea se usa rvs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.binom.pmf(20, 100, 1/6) #P(x = 20), n = 100, p = 1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = stats.binom(100, 1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.pmf(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.rvs(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x2, x3  = np.arange(51), np.arange(101), np.arange(201)\n",
    "y, y2, y3  = stats.binom.pmf(x, 50, 1/6), stats.binom.pmf(x2, 100, 1/6), stats.binom.pmf(x3, 200, 1/6) \n",
    "fig, ax = plt.subplots(3)\n",
    "\n",
    "ax[0].plot(x, y, 'or', ms = 1.9)\n",
    "ax[1].plot(x2, y2, 'ob', ms = 1.9)\n",
    "ax[2].plot(x3, y3, 'og', ms = 1.9)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_xlim([0, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np.arange(51), np.arange(101), np.arange(201)]\n",
    "y = [stats.binom.pmf(x[0], 50, 1/6), stats.binom.pmf(x[1], 100, 1/6), stats.binom.pmf(x[2], 200, 1/6)]\n",
    "fig, ax = plt.subplots(3)\n",
    "mean = [stats.binom.mean(50, 1/6), stats.binom.mean(100, 1/6), stats.binom.mean(200, 1/6)]\n",
    "std = [stats.binom.std(50, 1/6), stats.binom.std(100, 1/6), stats.binom.std(200, 1/6)]\n",
    "color = ['or', 'ob', 'og']\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].plot(x[i], y[i], color[i], ms = 1.9)\n",
    "    ax[i].set_xlim([0, 50])\n",
    "    ax[i].axvline(x = mean[i])\n",
    "    ax[i].fill_between(x[i], y[i], where = (x[i] > (mean[i] - std[i])) & (x[i] < (mean[i] + std[i])),\n",
    "                       color = color[i][-1], alpha = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como Ejemplo supongamos que tenemos una urna con 100 bolas, 40 rojas y 60 blancas, si tomamos al azar una bola anotamos su color y lo devolvemos, llamemos al caso sacar una bola roja como el caso de éxito y repitamos el experimento 10 veces, en este caso nuestra variable aleatoria $X$ que cuente el número de veces que sacamos una bola roja seguirá una distribución $B(10, 0.4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = binom(10, 0.4)\n",
    "bi.pmf(4) #probabilidad de sacer 4 rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidad de sacar al menos 4 rojas P(X >= 4) = 1 - P(X <= 3)\n",
    "bi.cdf(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - bi.cdf(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(X < 3) = P(X <= 2)\n",
    "bi.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución Geométrica\n",
    "\n",
    "la distribución de probabilidad del número $X$ de ensayos de Bernoulli con parámetro $p$ necesarios para obtener un éxito, la función de probabilidad de la distribución geométrica es:\n",
    "\n",
    "\n",
    "$$P(X = x) = q^x p$$\n",
    "\n",
    "Diremos entonces que $X$ sigue una distribución de probabilidad geométrica de parámetro $p$ y lo representaremos como:\n",
    "\n",
    "$$X \\sim Ge(p)$$\n",
    " \n",
    "En Python la función stats.geom implementa la distribución geométrica empezando en 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ge = stats.geom(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ge.pmf(1) #cuenta el número de intentos hasta el exito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.geom.pmf(0, 0.25, loc=-1) # De esta forma cuenta el número de fracasos hasta el primer exito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ge.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ge.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(51)\n",
    "y = stats.geom.pmf(x, 0.25)\n",
    "z = stats.geom.cdf(x, 0.25)\n",
    "fig, ax = plt.subplots(2)\n",
    "mean = stats.geom.mean(0.25)\n",
    "std = stats.geom.std(0.25)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[0].plot(x, y, 'or', ms = 1.9)\n",
    "ax[0].set_xlim([0, 50])\n",
    "ax[0].axvline(x = mean)\n",
    "ax[0].fill_between(x, y, where = (x > (mean - std)) & (x < (mean + std)),\n",
    "                   color = 'r', alpha = 0.25)\n",
    "\n",
    "ax[1].plot(x, z, 'ob', ms = 1.9)\n",
    "ax[1].set_xlim([0, 50])\n",
    "ax[1].axvline(x = mean)\n",
    "ax[1].fill_between(x, z, where = (x > (mean - std)) & (x < (mean + std)),\n",
    "                   color = 'b', alpha = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución de Poisson\n",
    "\n",
    "La distribución de Poisson es una distribución de probabilidad discreta que se aplica a las ocurrencias de algún suceso durante un intervalo determinado. Nuestra variable aleatoria $X$ representará el _número de ocurrencias de un suceso en un intervalo determinado, el cual podrá ser tiempo, distancia, área, volumen o alguna otra unidad similar o derivada de éstas._\n",
    "\n",
    "La variable aleatoria discreta $X$ debe cumplir ciertos requisitos:\n",
    "\n",
    "- Debe ser un evento aleatorio\n",
    "- Los sucesos que estamos estudiando deben ser **independientes**\n",
    "\n",
    "La probabilidad de nuestra variable aleatoria X viene dada por la siguiente expresión: \n",
    "\n",
    "$$P(X, \\lambda) = \\frac{e^{-\\lambda}\\lambda^X}{X!}$$\n",
    "\n",
    "- X es el número de ocurrencias del evento estudiado\n",
    "- $\\lambda$ es un parámetro positivo que representa el número de veces que se espera que ocurra el fenómeno durante un intervalo dado. Por ejemplo, si el suceso estudiado tiene lugar en promedio 4 veces por minuto y estamos interesados en la probabilidad de que ocurra k veces dentro de un intervalo de 10 minutos, usaremos un modelo de distribución de Poisson con $\\lambda$ = 10×4 = 40.\n",
    "\n",
    "Podemos notar que tanto el valor esperado como la varianza de una variable aleatoria con distribución de Poisson son iguales a $\\lambda$. También se tiene que se cumple que $\\displaystyle\\sum_{x=1}^{\\infty} P(X,\\lambda) = 1$. Algunos ejemplos de eventos que siguen una distribución de Poisson son:\n",
    "\n",
    "- El número de llamadas telefónicas en una central telefónica por minuto.\n",
    "- El número de mutaciones de determinada cadena de ADN después de cierta cantidad de radiación.\n",
    "- El número de núcleos atómicos inestables que se han desintegrado en un determinado período.\n",
    "- El número de estrellas en un determinado volumen de espacio.\n",
    "\n",
    "\n",
    "Si tenemos una distribución Binomial $B(n, p)$ donde $n$ sea relativamente grande y $p$ relativamente pequeño, se puede aproximas dicha binomial usando una Poisson con parámetro $\\lambda = np$. No hay un criterio específico para realizar la aproximación pero se suele decir que si $n \\geq 30$, $np \\geq 10$ y $p \\leq 0.05$ la Poisson ya es una buena aproximación de la binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = stats.poisson(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.pmf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(51)\n",
    "y = P.pmf(x)\n",
    "z = P.cdf(x)\n",
    "fig, ax = plt.subplots(2)\n",
    "mean = P.mean()\n",
    "std = P.std()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[0].plot(x, y, 'or', ms = 1.9)\n",
    "ax[0].set_xlim([0, 50])\n",
    "ax[0].axvline(x = mean)\n",
    "ax[0].fill_between(x, y, where = (x > (mean - std)) & (x < (mean + std)),\n",
    "                   color = 'r', alpha = 0.25)\n",
    "\n",
    "ax[1].plot(x, z, 'ob', ms = 1.9)\n",
    "ax[1].set_xlim([0, 50])\n",
    "ax[1].axvline(x = mean)\n",
    "ax[1].fill_between(x, z, where = (x > (mean - std)) & (x < (mean + std)),\n",
    "                   color = 'b', alpha = 0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ejemplo__\n",
    "\n",
    "\n",
    "Durante la segunda guerra mundial, Alemania bombardeaba Inglaterra desde Calaes (Francia) utilizando los cohetes V1 y V2, siendo estos el primer misil guiado que se utilizó en la guerra  y el primer misil balístico de combate. Con la finalidad de descubrir si los Nazis podían elegir los objetivos de dichos ataques o estaban atacando a ciegas se dividió el sur de Londres en 576 regiones con la misma extensión de $0.25 km^2$, a lo largo de la contienda impactaron en esas regiones un total de 535 bombas V1 y V2.\n",
    "\n",
    "- Si se selecciona una región al azar, ¿cuál es la probabilidad de que fuese blanco de las bombas en dos ocasiones?\n",
    "- ¿Cuál es la probabilidad de que la región no recibiera ningún impacto?\n",
    "- según lo anterior, cuantas de las 576 regiones se espera que reciban 2 impactos, y cuantas ninguno?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x - número de impactor por área\n",
    "#lambda \n",
    "l = 535/576\n",
    "#P(2, l)\n",
    "p2 = stats.poisson.pmf(2, l)\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = stats.poisson.pmf(0, l)\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "576 *p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "576 * p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el análisis teórico si los bombardeos, se espera que alrededor de 98 regiones sean bombardeadas 2 veces, y que alrededor de 228 no sean bombardeadas. Los datos reales fueron que 93 regiones fueron bombardeadas 2 veces y 229 no fueron bombardeadas, por lo que se llega a a conclusión de que los alemanes no apuntaban los misiles, estaban atacando al azar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución hipergeométrica\n",
    "\n",
    "\n",
    "La distribución hipergeométrica es una distribución discreta relacionada con muestreos aleatorios y sin reemplazo. Suponga que se tiene una población de $N$ elementos de los cuales, $d$ pertenecen a la categoría $A$ y $N-d$ a la $B$. La distribución hipergeométrica mide la probabilidad de obtener $x$ ($ 0\\leq x\\leq d$) elementos de la categoría A en una muestra sin reemplazo de n elementos de la población original.\n",
    "\n",
    "Las características de una distribución hipergeómetrica son:\n",
    "\n",
    "- La población debe tener un número finito de elementos $N$.\n",
    "- se toma una muestra aleatoria de $n$ elementos de la población\n",
    "- Existen $d$ elementos con una característica deseada en la población.\n",
    "- En la muestra $n$ hay $x$ elementos con la caractarística deseada\n",
    "\n",
    "\n",
    "La función de probabilidad de una variable aleatoria con distribución hipergeométrica es igual a:\n",
    "\n",
    "$$P(X=x)=\\frac {\\binom{d}{x}  \\binom{N-d}{n-x}}{N \\choose n}$$\n",
    "\n",
    "Donde $\\displaystyle N$ es el tamaño de población, $n$ es el tamaño de la muestra extraída, $d$ es el número de elementos en la población original que pertenecen a la categoría deseada y $x$ es el número de elementos en la muestra que pertenecen a dicha categoría. La notación $\\displaystyle {a \\choose x}$ al número de combinaciones posibles al seleccionar $x$ elementos de un total $a$.\n",
    "\n",
    "El valor esperado de una variable aleatoria $X$ (media) que sigue una distribución hipergeométrica es:\n",
    "\n",
    "$$\\displaystyle E[X]={\\frac {nd}{N}}$$\n",
    "\n",
    "y su varianza:\n",
    "\n",
    "$$Var[X]=\\bigg (\\frac{N-n}{N-1}\\bigg )\\bigg (\\frac {nd}{N}\\bigg )\\bigg (1-\\frac{d}{N}\\bigg )$$\n",
    "En la fórmula anterior, definiendo\n",
    "\n",
    "$$p=\\frac {d}{N}$$\n",
    "y\n",
    "\n",
    "$$q=1-p$$\n",
    "se obtiene\n",
    "\n",
    "$$Var[X]=npq\\frac{N-n}{N-1}$$\n",
    "$$E[X]= np$$\n",
    "La distribución hipergeométrica es aplicable a muestreos sin reemplazo y la binomial a muestreos con reemplazo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ejemplo__\n",
    "\n",
    "Se reparten 5 cartas de una baraja de 52, ¿cuál es la probabilidad de obtener un poker de aces (4 aces) si se sabe que al menos ya salieron 3?\n",
    "\n",
    "Se quiere calcular la probabilidad $P(x = 4 | x \\ge 3)$, por teorema de bayes sabemos que:\n",
    "\n",
    "\n",
    "$$P(x = 4 | x \\ge 3) = \\frac{P(x = 4)P(x \\ge 3 | x = 4)}{P(x \\ge 3)}$$\n",
    "\n",
    "notando que $P(x \\ge 3 | x = 4)$ = 1 el problema se reduce a calcular:\n",
    "$$P(x = 4 | x \\ge 3) = \\frac{P(x = 4)}{P(x \\ge 3)}$$\n",
    "\n",
    "\n",
    "Y $P(x \\ge 3) = P(x = 4) + P(x = 3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, d, n = 52, 4, 5\n",
    "hy = stats.hypergeom(N, d, n)\n",
    "p4 = hy.pmf(4) #x, N, d, n\n",
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = hy.pmf(3) + hy.pmf(4)\n",
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4  / p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuciones continuas notables\n",
    "\n",
    "\n",
    "#### Distribución uniforme\n",
    "\n",
    "Una variable aleatoria $X$ tiene distribución uniforme sobre un intervalo real $(a, b)$, si su función de densidad es:\n",
    "\n",
    "\n",
    "$$f(X) = \\frac{1}{b - a}$$\n",
    "\n",
    "para $x \\in (a, b)$, si $X$ sigue una distribución uniforme lo denotaremos por $X \\sim U(a, b)$. Noten que el valor esperado de esta distribución es $E(x) = \\frac{a + b}{2}$ y su varianza $var(x) = \\frac{(b - a)^2}{12}$ \n",
    "\n",
    "\n",
    "Dentro de Python la función uniform nos permite generar distribuciones uniformes pero utilizando los parámetros _loc_ y _scale_ que seran $loc = a$, y $scale = b - a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = stats.uniform(-1, 2) #→ U(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.pdf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.rvs(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2)\n",
    "y = U.pdf(x)\n",
    "z = U.cdf(x)\n",
    "fig, ax = plt.subplots(2)\n",
    "mean = U.mean()\n",
    "std = U.std()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[0].plot(x, y, 'r', ms = 1.9)\n",
    "ax[0].set_xlim([-2, 2])\n",
    "ax[0].axvline(x = mean)\n",
    "ax[0].fill_between(x, y, where = (x > (mean - std)) & (x < (mean + std)),\n",
    "                   color = 'r', alpha = 0.25)\n",
    "\n",
    "ax[1].plot(x, z, 'b', ms = 1.9)\n",
    "ax[1].set_xlim([-2, 2])\n",
    "ax[1].axvline(x = mean)\n",
    "ax[1].fill_between(x, z, where = (x > (mean - std)) & (x < (mean + std)),\n",
    "                   color = 'b', alpha = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h4>Distribución normal</h4>\n",
    "\n",
    "\n",
    "La distribución normal o distribución gaussiana es una de las distribuciones de probabilidad de variable continua que con más frecuencia aparece en estadística y en la teoría de probabilidades. La función distribución de probabilidad está dada por:\n",
    "\n",
    "$$f(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{\\frac{-1}{2} \\big(\\frac{x - \\mu}{\\sigma}\\big)^2}$$\n",
    "\n",
    "Donde $\\mu$ es la media y $\\sigma$ es la desviación estándar. La distribución de probabilidad _normal estandar_ es aquella que tiene por media $0$ y por desviación estándar $1$. Al ser una distribución de probabilidad el área bajo la curba que resulta de graficar $f$ es igual a $1$ y podemos asociar la integral $\\displaystyle\\int_{-\\infty}^{a} f(x)\\, dx$ con el valor de la probabilidad de que la variable $x$ tome un valor menor o igual a $a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sig = 0, 1\n",
    "norm = stats.norm(mu, sig)\n",
    "x = np.linspace(norm.ppf(0.01), norm.ppf(0.99))\n",
    "y = norm.pdf(x)\n",
    "fig, ax = plt.subplots()\n",
    "ax.axvline(x = norm.mean())\n",
    "ax.fill_between(x, y, where = (x <= 1) & (x >= -1),\n",
    "                alpha = 0.25, color = 'r')\n",
    "ax.plot(x, y, color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(norm.ppf(0.01), norm.ppf(0.99))\n",
    "y = norm.pdf(x)\n",
    "z = norm.cdf(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, color = 'g')\n",
    "ax.plot(x, z, color = 'r')\n",
    "ax.fill_between(x, y, where = (x <= 0), alpha = .25, color = 'g')\n",
    "ax.axhline(0.5, color = 'k', alpha = 0.5)\n",
    "ax.axvline(0, color = 'k', alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $X \\sim N(\\mu, \\sigma)$ entonces $\\frac{X - \\mu}{\\sigma} \\sim N(0, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Más métricas</h2>\n",
    "\n",
    "<h3>Asimetría de una variable Aleatoria</h3>\n",
    "\n",
    "\n",
    "Una veriable aletaria **asimetría positiva** si su función de probabilidad o densidad presenta una cola a la derecha y **asimetría negativa** si su función de densidad o probabilidad presenta una cola a la izquierda.\n",
    "\n",
    "<img src = https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Posiciones_relativas_de_par%C3%A1metros_centrales.svg/1920px-Posiciones_relativas_de_par%C3%A1metros_centrales.svg.png>\n",
    "\n",
    "\n",
    "La asimetría de una variable aleatoria $X$ se calcula a partir de sus momentos centrales de orden 2 y 3.\n",
    "\n",
    "$$\\gamma_1 = E\\left(\\left( \\frac{X - \\mu}{\\sigma}\\right)^3\\right) = \\frac{\\mu_3}{\\sigma^3}$$\n",
    "\n",
    "Este es el **coeficiente de asimetría de Pearson.** Y se tiene que una variable aleatoria tiene **asimetría positiva** si $\\gamma_1 > 0$ y **asimetría negativa** si $\\gamma_1 < 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ejemplo: Distribución exponencial</h4>\n",
    "\n",
    "$$X \\sim Exp(\\lambda)$$\n",
    "\n",
    "$$f_{X}(x)=\\lambda e^{-\\lambda x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.expon(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "x = np.linspace(1, 5)\n",
    "y = dist.pdf(x)\n",
    "\n",
    "sns.lineplot(x = x, y = y, ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(y)\n",
    "y.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Curtosis de una variable Aleatoria</h3>\n",
    "\n",
    "La curtosis de una variable aleatoria es una medida de como son las colas de su función de densidad.\n",
    "\n",
    "Dicho de otra manera, buscamos medir de alguna manera la tendencia que tiene una variable aleatoria a tener **outliers.**\n",
    "\n",
    "La manera estandar de medir la curtosis de una variable aleatoria $X$ es apartir de su momento central de cuarto orden:\n",
    "\n",
    "$$\\gamma_2 = E\\left(\\left(\\frac{X - \\mu}{\\sigma} \\right)^4\\right) = \\frac{\\mu_4}{\\sigma^4}$$\n",
    "\n",
    "\n",
    "A la expresion anterior se le denomina **medida de curtosis de Pearson**\n",
    "\n",
    "- Diremos que una variable aleatoria no tiene exceso de curtosis o es **mesocúrtica** si $\\gamma_2 \\approx 3$\n",
    "\n",
    "- Diremos que una variable aleatoria tiene exceso positivo de curtosis o es **leptocúrtica** si $\\gamma_2 > 3$\n",
    "\n",
    "- Diremos que una variable aleatoria tiene exceso negativo de curtosis o es **platicúrtica** si $\\gamma_2 < 3$\n",
    "\n",
    "\n",
    "<img src = https://www.lifeder.com/wp-content/uploads/2020/03/curtosis.jpg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.norm(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "x = np.linspace(-2, 2, 1000)\n",
    "y = dist.pdf(x)\n",
    "\n",
    "sns.lineplot(x = x, y = y, ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kurtosis(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Entropía de una variable aleatoria</h3>\n",
    "\n",
    "\n",
    "Sí, entropía. Al igual que en la física, la entropía juega un papel fundamental en la teoría de la información, y es que están relacionadas (aunque no lo parezca). La idea de entropía se describe a menudo como \"la cantidad de desorden\", lo cual es ciertamente horrible porque \"desorden\" es un término subjetivo.\n",
    "\n",
    "Me gusta más definir la entropía de un sistema físico como el número de microestados compatibles con el macroestado. Esta es, en palabras más comunes, una medida de información que no conocemos.\n",
    "\n",
    "Imagina que lanzas un dado y observas qué cara cae, es fácil entender que todas las caras tienen la misma probabilidad de observar. Pero si tiramos dos dados y observamos la suma de sus caras, ¿ocurre lo mismo?\n",
    "\n",
    "\n",
    "La respuesta es no, solo hay una forma en que el resultado es dos ($ 1 + 1 $) pero hay 3 formas en las que el resultado es 3 ($ 1 + 3 $, $ 2 + 2 $, $ 3 + 1 $), vamos a llamr al estado _el resultado es 4_ como **macroestado** y los estados $ 1 + 3 $, $ 2 + 2 $ y $ 3 + 1 $ los **microestados** compatibles.\n",
    "\n",
    "Entonces, hay un estado que es más probable que ocurra (que la suma sea 7) y, sin embargo, si este macroestado ocurre, tendremos una gran incertidumbre sobre el microestado de nuestro experimento (¿cuál de las 6 combinaciones posibles es la que está frente a nosotros?), entonces decimos que la el estado _la suma igual a 7_ tiene una gran **incertidumbre**, es decir, tiene una **gran entropía**, por otro lado si el resultado es que la suma es igual a 2 solo hay un posible microestado, no tenemos incertidumbre o tenemos una **baja entropía**.\n",
    "\n",
    "\n",
    "Entonces, como acabamos de ver, lo más probable al realizar nuestro experimento es que obtengamos un estado con alta entropía. Felicitaciones, acaba de deducir la **segunda ley de la termodinámica** usando dados.\n",
    "\n",
    "Y esto, ¿qué tiene que ver con la información? Bueno, si observas un macroestado, _la suma es igual a dos_, y luego alguien te dice que uno de los dados cae 1, eso no te sorprende, no te da información, pero si el macroestado es _la suma es igual a 7_, saber que uno de los callos de dados 3 proporciona mucha información, ahora sabes que el segundo callo de dados 4.\n",
    "\n",
    "La entropía (Shannon) se define mediante la siguiente fórmula:\n",
    "\n",
    "$$ H (S) = \\ sum_{i = 1} ^ {c} - p_i \\ log_{2} {p_i} $$\n",
    "\n",
    "La entropía toma el valor máximo cuando todos los resultados son igualmente probables, y toma su valor mínimo (0) cuando tenemos certeza absoluta.\n",
    "\n",
    "\n",
    "Ahora la entropia es una medida de la **incertidumbre** de una variable aleatoria.\n",
    "\n",
    "Supongamos que tenemos una variable aleatoria $X$ discreta con valores enteros:\n",
    "\n",
    "$$D_X = \\{ 1, 2, 3, \\cdots, n \\}$$\n",
    "\n",
    "Sea $k \\in D_X$ un valor de la variable. Estamos interesados en cuantificar la incertidumbre del suceso $A_k = \\{ X = k \\}$, entre menos incertidumbre tenga $A_k$ más alta sera su probabilidad, y cuanto más incertidumbre menos probable será de obserbar $A_k$.\n",
    "\n",
    "$$I(A_k) = \\ln\\left(\\frac{1}{P(X = k)} \\right) = - \\ln \\left(P(X = k)\\right)$$\n",
    "\n",
    "\n",
    "Sea $X$ una variable aleatoria con función de densidad $f_X(x)$ en el caso continuo o función de probabilidad $P_X(x)$ en el caso discreto. Definimos la **Entropía** de $X$ como:\n",
    "\n",
    "$$H_X = E\\left(- \\ln \\left(f_x(x)\\right)\\right) = \\int_{- \\infty}^{\\infty} - \\ln \\left(f_x(x)\\right) f_X(x) dx$$\n",
    "\n",
    "$$H_X = E\\left(- \\ln \\left(P_x(x)\\right)\\right) = \\sum - \\ln \\left(P_x(x)\\right) P_x(x)$$\n",
    "\n",
    "\n",
    "<h4>Ejemplo: Entrpía de una Bernoulli</h4>\n",
    "\n",
    "Sea $X$ una variable de Bernoulli de parámetro $p$ y recordando que $P(0) = 1 - p$ y $P(1) = p$\n",
    "\n",
    "La entropía de $X$ será:\n",
    "\n",
    "$$H_X = E\\left(- \\ln \\left(P_x(x)\\right)\\right) = - (1 - p) \\ln(1 - p) - p \\ln(p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_bernouli(p):\n",
    "    return -(1 - p) * np.log(1 - p) - p * np.log(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = H_bernouli(x)\n",
    "\n",
    "sns.lineplot(x = x, y = y, ax = ax)\n",
    "ax.axvline(0.5, color = 'r', alpha = 0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectores Aleatorios\n",
    "\n",
    "### Vectores Aleatorios Bidimensionales\n",
    "\n",
    "Recordemos que una variable analeatoria unidimensional es una función que asigna a cada resultado de un experimento aleatorio un valor numérico $X: \\Omega \\to \\mathbb{R}$, Ahora definiremos un variable aleatoria bidimensional como una función $W$ tal que $W: \\Omega \\to \\mathbb{R}^2$, y la podemos visualizar como una pareja ordenada $(X, Y)$ donde $X$ y $Y$ son variables aleatoreas unidimensionales.\n",
    "\n",
    "\n",
    "Por ejemplo, podemos tomar un estudio donde analizamos la altura y el peso de un grupo de personas, o por ejemplo: Suponga un experimento aleatorio en el que se tiran dos dados de 6 caras, y $S$ es la variable aleatoria que mide la suma de las caras de los dados, y $P$ la variable aleatoria que mide el producto de las caras de los dados. Entonces $(S, P)$ es una variable aleatoria bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de distribución conjunta\n",
    "\n",
    "\n",
    "Suponga que $(X, Y)$ son una VAB, entonces vamos a extender el concepto de función de distribución de una variable a nuestro caso bidimensional, la extensión será la función de distribución conjunta $F_{XY}: \\mathbb{R}^2 \\to \\mathbb{R}$ y que vamos a definir como:\n",
    "\n",
    "$$F_{XY}(x, y) = P(X \\leq x, Y \\leq y)$$\n",
    "\n",
    "\n",
    "Vamos a dar un par de propiedades de $F_{XY}$:\n",
    "\n",
    "\n",
    "- $F_{XY}(x, -\\infty) = F_{XY}(-\\infty, y) = 0$\n",
    "- $F_{XY}(\\infty, \\infty) = 1$\n",
    "\n",
    "También definiremos a $X$ y $Y$ como las variables aleatorias marginales, y cada una va a tener su función de distribución marginal que está definida por:\n",
    "\n",
    "\n",
    "- $F_X(x) = F_{XY}(x, \\infty)$\n",
    "- $F_Y(y) = F_{XY}(\\infty, y)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Aleatoria Bidimensional Discreta\n",
    "\n",
    "Retomemos el ejemplo del dado y la variable $(S, P)$, dicha variable es discreta, ya que solo puede tomar determinados valores numerables, veamos los valores que puede tomar $(S, P)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = [(i, j) for i in range(1, 7) for j in range(1, 7)]\n",
    "omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {(elem[0] + elem[1], elem[0] * elem[1]) for elem in omega}\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir la función de probabilidad conjunta $P_{XY}: \\mathbb{R}^2 \\to \\mathbb{R}$ como:\n",
    "\n",
    "\n",
    "$$P_{XY}(x, y) = P(X = x, Y = y)$$\n",
    "\n",
    "\n",
    "Note que $$\\sum \\sum P_{XY}(x_i, y_i) = 1$$\n",
    "\n",
    "Y también vamos a extender el concepto de función de distribución, a la función de distribución conjunta $F_{XY}$ como:\n",
    "\n",
    "\n",
    "$$F_{XY}(x, y) = \\sum_{x_i \\leq x | y_i \\leq y} P_{XY}(x_i, y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marginales de una V.A.B.D.\n",
    "\n",
    "\n",
    "Sea $(X, Y)$ una V.A.B.D. con $P_{XY}$, entonces la función de probabilidad conjunta tiene suficiente información para obtener la función de probabilidad de las marginales $X$, y $Y$. Las funciones de probabilidad marginales $P_X(x)$ y $P_Y(y)$ serán:\n",
    "\n",
    "\n",
    "- $P_X(x_i) = \\sum_{j = 1} P_{XY}(x_i, y_j)$\n",
    "- $P_Y(y_j) = \\sum_{i = 1} P_{XY}(x_i, y_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Aleatoria Continua Bidimensional\n",
    "\n",
    "De forma análoga como definimos las variables continuas en una dimensión, diremos que $(X, Y)$ es una V.A.B.C. si existe una función $f_{XY} = \\mathbb{R}^2 \\to \\mathbb{R}$, tal que:\n",
    "\n",
    "$$P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{XY}(x, y) dxdy$$\n",
    "\n",
    "Y de forma análoga definiremos la función de distribución $F_{XY}(x, y)$ como:\n",
    "\n",
    "\n",
    "$$F_{XY}(x, y) = \\int_{-\\infty}^x \\int_{-\\infty}^y f_{XY}(u, v) dudv$$\n",
    "\n",
    "\n",
    "Para el caso continuo tambián se van a definir las variables aleatorias marginales $X$ y $Y$, y las funciones de densidad marginales serán:\n",
    "\n",
    "- $F_X(x) = \\int_{-\\infty}^{\\infty} f_{XY}(x, y) dy$\n",
    "- $F_Y(y) = \\int_{-\\infty}^{\\infty} f_{XY}(x, y) dx$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribución Gaussiana Bidimensional\n",
    "\n",
    "\n",
    "Suponga que $(X, Y)$ es una V.A.B.C., diremos que $(X, Y)$ es bidimensional gaussiana de parámetro $\\rho$ si la función de densidad conjunta es:\n",
    "\n",
    "$$f_{XY}(x, y) = \\frac{1}{2 \\pi \\sqrt{1 - \\rho^2}} e^{- \\frac{x^2 - 2\\rho xy + y^2}{2 (1 - \\rho^2)}}$$\n",
    "\n",
    "\n",
    "\n",
    "Noten que $f_{XY}$ tiene un máximo absoluto en $(0, 0)$, dicho máximo toma un valor:\n",
    "\n",
    "$$f_{XY}(0, 0) = \\frac{1}{2 \\pi \\sqrt{1 - \\rho^2}}$$\n",
    "\n",
    "\n",
    "Y dicho máximo alcanza el mínimo valor posible cuando $\\rho = 0$. Otra propiedad que cabe resaltar de la Distribución Gaussiana bidimensional es que las funciones de densidad marginales siempre son una normal de media 0 y desviación estándar 1, es decir:\n",
    "\n",
    "\n",
    "- $F_X(x) \\sim N(0, 1) \\to \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-x}{2}}$\n",
    "- $F_Y(y) \\sim N(0, 1) \\to \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-y}{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valor esperado de Variables Aleatorias Bidimensionales\n",
    "\n",
    "\n",
    "En el caso de variables aleatorias bidimensionales lo que nos interesa es saber cómo varían $X$ y $Y$ juntas, es decir ver si estan correlacionadas. Supongamos que tenemos $(X, Y)$ una VAB y $Z = g(X, Y)$\n",
    "\n",
    "\n",
    "- $E(Z) = \\sum \\sum g(x_i, y_i)P_{XY}(x_i, y_i)$\n",
    "- $E(Z) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} g(x_i, y_i)f_{XY}(x_i, y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covarianza de Variables aleatorias Bidimensionales\n",
    "\n",
    "\n",
    "Vamos a Definir la covarianza de una VAB como:\n",
    "\n",
    "$$Cov(X, Y) = E((X - \\mu_x)(Y - \\mu_y))$$\n",
    "\n",
    "$$Cov(X, Y) = E(XY) - \\mu_x \\mu_y$$\n",
    "\n",
    "Si mis variables son independientes $Cov(X, Y) = 0$, sin embargo que $Cov(X, Y) = 0$ no implica que $X$ y $Y$ sean independientes. La covarianza nos va a servir como una medida de que tan correlacionadas están nuestras variables, hay un propiedad que nos relaciona la varianza de las variables marginales con la covarianza conjunta, esta es la siguiente expresión:\n",
    "\n",
    "\n",
    "$$Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)$$\n",
    "$$Var(X - Y) = Var(X) + Var(Y) - 2Cov(X, Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlación entre Variables\n",
    "\n",
    "\n",
    "Noten que la covarianza es una medida que depende de la escala, es decir depende de las unidades con las que esta medida la variables aleatorias en cuestión, esto puede provocar que la covarianza nos de pista de una correlación más grande entre las variables que la que realmente tienen, para evitar esto vamos a tratar de normalizar la covarianza definiendo el coeficiente de correlación. Sea $(X, Y)$ una VAB, definiremos el coeficiente de correlación $\\rho_{XY}$ como:\n",
    "\n",
    "\n",
    "$$\\rho_{XY} = \\frac{Cov(X, Y)}{\\sqrt{Var(X)} \\sqrt{Var(Y)}}$$\n",
    "\n",
    "\n",
    "La ventaja del coeficiente de correlación es que es adimensional, lo que evita el problema de la escala que teníamos con la covarianza. El coeficiente de correlación siempre toma valores entre $-1 \\leq \\rho_{XY} \\leq 1$. Noten que en la normal bidimensional el coeficiente de correlación es el parámetro $\\rho$ que aparece en la expresión, y entonces para $\\rho \\neq 0$ se tiene que las variables $X$, y $Y$ son dependientes:\n",
    "\n",
    "\n",
    "$$f_{XY}(x, y) = \\frac{1}{2 \\pi \\sqrt{1 - \\rho^2}} e^{- \\frac{x^2 - 2\\rho xy + y^2}{2 (1 - \\rho^2)}}$$\n",
    "\n",
    "\n",
    "Tengan en cuenta que si se tienen dos variables $X$ y $Y$ independientes entonces $\\rho = 0$, pero un valor $\\rho = 0$ no implica necesariamente independencia entre las variables.\n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Veaamos un ejemplo de una VAB con $\\rho_{XY} = 0$ pero donde $X$ y $Y$ no son independientes.\n",
    "\n",
    "$$\n",
    "f_{XY}(x, y)= \\left\\{ \n",
    "\\begin{array}{lcc}\n",
    "\\frac{3}{8} (x^2 + y^2)&   si  & (x, y) \\in [-1, 1] \\times [-1, 1] \\\\\n",
    "0&   & \\text{En caso contrario}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "x = symbols('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 2*x\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.integrate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.integrate((x, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = symbols('x, y')\n",
    "\n",
    "f = (3/8)*(x**2 + y**2)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten que según la definición de funciones de densidad marginales:\n",
    "\n",
    "- $f_X(x) = \\int_{-\\infty}^{\\infty} f_{XY}(x, y) dy$\n",
    "- $f_Y(y) = \\int_{-\\infty}^{\\infty} f_{XY}(x, y) dx$\n",
    "\n",
    "pero en este caso fuera del intervalo $[-1, 1]$ todos los valores son 0 tanto para $X$ como para $Y$ por lo que nuestras marginales serán:\n",
    "\n",
    "\n",
    "- $f_X(x) = \\int_{-1}^{1} f_{XY}(x, y) dy$\n",
    "- $f_Y(y) = \\int_{-1}^{1} f_{XY}(x, y) dx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = f.integrate((y, -1, 1))\n",
    "fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy = f.integrate((x, -1, 1))\n",
    "fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora vamos a calcular los valores esperados para las marginales.\n",
    "\n",
    "$$E(X) = \\int_{-\\infty}^{\\infty} xf_X(x)dx$$\n",
    "\n",
    "De forma similar al caso anterior debido al dominio de $f_{XY}$ basta integrar en $[-1, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex = (x * fx).integrate((x, -1, 1))\n",
    "Ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ey = (y * fy).integrate((y, -1, 1))\n",
    "Ey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a calcular el valor esperado para $Z = XY$, recordando:\n",
    "\n",
    "$$E(Z) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} g(x_i, y_i)f_{XY}(x_i, y_i)dxdy$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exy = (x * y * f).integrate((x, -1, 1))\n",
    "Exy = Exy.integrate((y, -1, 1))\n",
    "Exy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noten entonces que:\n",
    "\n",
    "$$Cov(X, Y) = E(XY) - \\mu_x \\mu_y = 0$$\n",
    "\n",
    "Y por tanto el coeficiente de correlación $\\rho_{XY}$ también es 0, pero las variables X e Y no son independientes. Recordemos que de forma análoga a los eventos, donde decíamos que $A$ y $B$ son independientes si $P(A \\cap B) = P(A)P(B)$ en este caso diremos que las marginales $X$ y $Y$ son independientes si $f_{XY} = f_{x}f_{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx * fy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f == (fx * fy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ley de los grandes Números\n",
    "\n",
    "\n",
    "A medida que aumenta el número de repeticiones de un experimento, el promedio de las medias muestrales se aproxima mejor a la media de la población.\n",
    "\n",
    "$$\\frac{1}{n} \\sum \\bar{x}_i \\to \\mu$$\n",
    "$$\\bar{X_n} \\to \\mu$$\n",
    "\n",
    "- Cualquier muestra (o experimento) es sensible a la variabilidad del muestreo, ruido, etc.\n",
    "\n",
    "    - Esto significa que es poco probable que una muestra o experimento proporcione una buena estimación de la media real de la población.\n",
    "\n",
    "- Pero muestrear muchas veces puede proporcionar una medida precisa de la media real de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Illegal die\n",
    "probabilities = np.array([1/4, 1/4, 1/8, 1/8, 1/8, 1/8])\n",
    "values        = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "\n",
    "E = (values * probabilities).sum()\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = np.random.choice(values, size = 1_000_000, p = probabilities)\n",
    "\n",
    "## experiment: draw larger and larger samples\n",
    "\n",
    "k = 5000  # maximum number of samples\n",
    "sampleAve = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    sample = np.random.choice(population, size = i + 1) \n",
    "    sampleAve[i] = np.mean(sample)\n",
    "\n",
    "\n",
    "    \n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "ax.plot(sampleAve, 'b', label = 'Sample average')\n",
    "ax.axhline(E, color = 'r', alpha = 0.7, linewidth = 4, label = 'expected value')\n",
    "ax.set_xlabel('Number of samples', fontsize = 15)\n",
    "ax.set_ylabel('Value', fontsize = 15)\n",
    "ax.set_ylim([E - 1, E + 1])\n",
    "ax.legend()\n",
    "\n",
    "# mean of samples converges to population estimate quickly:\n",
    "print( np.mean(sampleAve) )\n",
    "print( np.mean(sampleAve[:9]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate population data with known mean\n",
    "gauss = stats.norm(1.64, 0.15)\n",
    "populationN = 1_000_000\n",
    "population = gauss.rvs(populationN)\n",
    "\n",
    "# get means of samples\n",
    "samplesize   = 30\n",
    "number_of_exps = 500\n",
    "samplemeans  = np.zeros(number_of_exps)\n",
    "\n",
    "for i in range(numberOfExps):\n",
    "    # get a sample and compute its mean\n",
    "    samplemeans[i] = np.mean(np.random.choice(population, samplesize))\n",
    "\n",
    "\n",
    "# show the results!\n",
    "fig, ax = plt.subplots(2, 1, figsize = (13, 8))\n",
    "\n",
    "ax[0].plot(samplemeans,'s-', label = 'Sample means')\n",
    "ax[0].axhline(gauss.mean(), color = 'r', linewidth = 3, alpha = 0.7, label = 'Population mean')\n",
    "ax[0].set_xlabel('Experiment number', fontsize = 15)\n",
    "ax[0].set_ylabel('mean value', fontsize = 15)\n",
    "ax[0].legend(prop={'size': 15})\n",
    "\n",
    "ax[1].plot(np.cumsum(samplemeans) / np.arange(1, number_of_exps + 1),'s-', label = 'Sample means')\n",
    "ax[1].axhline(gauss.mean(), color = 'r', linewidth = 3, alpha = 0.7, label = 'Population mean')\n",
    "ax[1].set_xlabel('Experiment number', fontsize = 15)\n",
    "ax[1].set_ylabel('mean value', fontsize = 15)\n",
    "ax[1].legend(prop={'size': 15});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a simular la ley de los grandes números simulando el lanzamiento de un dado, en este caso particular las variables $X_n$ seguirán una distribución de Bernoulli de parámetro $p = \\frac{1}{6}$ y va a contar cuantas veces obtenemos una cara en la tirada. En este caso cada una de las $X_i$ tendran el mismo valor esperado $E[X_i]= \\frac{1}{6}$, y vamos a suponer que nuestro caso de exito es que el dado salga en 3, entonces $X_i$ sera 1 si el dado cayo 3 en la i-ésima tirada y 0 en otro caso, entonces:\n",
    "\n",
    "$$\\bar{X_n} = \\frac{X_1 + X_2 + \\cdots + X_n}{n} = \\frac{\\text{número de exitos}}{\\text{número de tiradas}}$$\n",
    "\n",
    "Lo mismo sucede para cada cara del dado, y entonces lo que esperamos es que entre más tiradas hagamos:\n",
    "\n",
    "$$\\bar{X_n} \\to \\frac{1}{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(np.random.randint(1, 7, 10000))\n",
    "\n",
    "def rolls(d, n):\n",
    "    \n",
    "    aux = d[:n]\n",
    "    die = {}.fromkeys(aux)\n",
    "    \n",
    "    for k in die.keys():\n",
    "        die[k] = aux.count(k) / len(aux)\n",
    "        \n",
    "    return die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeplots(n):\n",
    "    \n",
    "    ax.cla()\n",
    "    \n",
    "    die = rolls(d, n)\n",
    "    pl = ax.bar(die.keys(), die.values(), color = ['r', 'g', 'b', 'brown', 'y', 'purple'])\n",
    "    ax.axhline(1/6, color = 'g', alpha = 0.5, label = 'Theoric value')\n",
    "    \n",
    "    \n",
    "    ax.set_title(\"Number of rolls: {}\".format(n))\n",
    "    ax.set_xlabel(\"Die Face\")\n",
    "    ax.set_ylabel(\"Relative Frequency\")\n",
    "    ax.set_ylim(0, 1 / 4)\n",
    "    ax.legend()\n",
    "    return (pl, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "values = range(10, 3000, 10)\n",
    "animation = FuncAnimation(fig, makeplots, values)\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema central del límite\n",
    "\n",
    "\n",
    "La distribución de las medias muestrales se aproxima a una distribución gaussiana, independientemente de la forma de la distribución de la población.\n",
    "\n",
    "\n",
    "$$Z = \\frac{\\bar{X_n} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\to N(0, 1)$$\n",
    "\n",
    "$$\\bar{X_n} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data\n",
    "\n",
    "# data\n",
    "N = 1_000_000\n",
    "data = np.random.randn(N) ** 2\n",
    "\n",
    "# show the distribution\n",
    "fig, ax = plt.subplots(2, 1, figsize = (13, 8))\n",
    "ax[0].plot(data,'.')\n",
    "\n",
    "\n",
    "ax[1].hist(data, 40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## repeated samples of the mean\n",
    "\n",
    "samplesize   = 30\n",
    "number_of_exps = 500\n",
    "\n",
    "samplemeans  = np.zeros(number_of_exps)\n",
    "\n",
    "for i in range(number_of_exps):\n",
    "    # get a sample and compute its mean\n",
    "    samplemeans[i] = np.mean(np.random.choice(data, samplesize))\n",
    "    \n",
    "\n",
    "    \n",
    "gauss = stats.norm(samplemeans.mean(), samplemeans.std())\n",
    "x = np.linspace(0.2, 2, 1000)\n",
    "# and show its distribution\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "ax.hist(samplemeans, bins = 30, density = True)\n",
    "ax.plot(x, gauss.pdf(x), color = 'r')\n",
    "ax.set_xlabel('Mean estimate', fontsize = 15)\n",
    "ax.set_ylabel('Count', fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
