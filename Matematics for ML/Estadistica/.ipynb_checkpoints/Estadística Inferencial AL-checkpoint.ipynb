{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadística Inferencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "\n",
    "- [Prueba de Hipótesis](#Prueba-de-Hipótesis)\n",
    "    - [¿Qué es una hipótesis y cómo se especifica una?](#¿Qué-es-una-hipótesis-y-cómo-se-especifica-una?)\n",
    "    - [La hipótesis nula](#La-hipótesis-nula)\n",
    "    - [P-valor](#P-valor)\n",
    "    - [Tipos de Hipótesis Alternativas](#Tipos-de-Hipótesis-Alternativas)\n",
    "    - [Tipos de Errores](#Tipos-de-Errores)\n",
    "    - [Prueba paramétrica vs no paramétrica](#Prueba-paramétrica-vs-no-paramétrica)\n",
    "    \n",
    "    \n",
    "- [Correlación](#Correlación)\n",
    "    - [Covarianza y correlación: fórmulas](#Covarianza-y-correlación:-fórmulas)\n",
    "    - [El problema con Pearson](#El-problema-con-Pearson)\n",
    "    \n",
    "    \n",
    "- [T-test](#T-test)\n",
    "    - [T-test de una muestra](#T-test-de-una-muestra)\n",
    "    - [T-test de dos muestras](#T-test-de-dos-muestras)\n",
    "    - [Wilcoxon signed-rank (T-test no paramétrico)](#Wilcoxon-signed-rank-(T-test-no-paramétrico))\n",
    "    \n",
    "    \n",
    "- [Intervalos de Confianza](#Intervalos-de-Confianza)\n",
    "    - [Calcular intervalos de confianza mediante fórmula.](#Calcular-intervalos-de-confianza-mediante-fórmula.)\n",
    "    - [Intervalos de confianza mediante bootstrapping.](#Intervalos-de-confianza-mediante-bootstrapping.)\n",
    "    \n",
    "    \n",
    "- [Ejercicio](#Ejercicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de Hipótesis\n",
    "\n",
    "\n",
    "Para que la estadística sea de utilidad no basta con calcular estadísticos, también se tienen que tomar decisiones basadas en los datos que estamos analizando, que acepte o rechace una afirmación relativa al valor de un parámetro. Estas afirmaciones que nos permiten aceptar o rechazar algo, reciben el nombre de hipótesis y el método estadístico de toma de decisión sobre una hipótesis recibe el nombre de prueba de hipótesis. Solemos tener dos hipótesis, una que queremos que ocurra, y otra que tomaremos si no ocurre la primera, la hipótesis alternativa $H_1$ es la hipótesis de la que busco evidencia de que ocurra y la hipótesis nula $H_0$ es la que rechazaremos si tenemos evidencia de la alternativa, _aceptaremos $H_0$ a menos que la evidencia diga lo contrario_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# ¿Qué es una hipótesis y cómo se especifica una?\n",
    "\n",
    "\n",
    "Una afirmación falsable que requiere verificación, generalmente a partir de datos experimentales u observacionales, y que permite realizar predicciones sobre observaciones futuras.\n",
    "\n",
    "\n",
    "\n",
    "## La hipótesis nula\n",
    "\n",
    "\n",
    "La _hipótesis nula_ es la _hipótesis aburrida_ ($H_0$), la hipótesis de que no sucede nada interesante en los datos.\n",
    "\n",
    "En la investigación, se especifica la _hipótesis alternativa_ ($H_1$).\n",
    "\n",
    "**En el análisis estadístico, prueba la hipótesis nula.**\n",
    "\n",
    "- $H_1$ → La gente comprará más widgets después de ver el anuncio $X$ en comparación con el anuncio $Y$.\n",
    "\n",
    "- $H_0$ → El tipo de anuncio no tiene ningún efecto en las compras de widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "h1 = stats.norm(2.3, 1)\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.plot(x, h1.pdf(x), label = '$H_1$')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-valor\n",
    "\n",
    "- ¿Qué posibilidades hay de que ocurra el valor de $H_1$ si $H_0$ es verdadero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax[0].plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax[0].axvline(1.8, label = '$H_1$', color = 'r', alpha = 0.7)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax[1].axvline(0.3, label = '$H_1$', color = 'g', alpha = 0.7)\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepto importante:\n",
    "\n",
    "- No podemos probar que $ H_1 $ sea cierto. Solo podemos calcular la probabilidad de que se pueda observar el estadístico de prueba asociado con $ H_1 $ dado que no hay un efecto verdadero.\n",
    "\n",
    "\n",
    "Los valores p son probabilidades. Van de 0 a 1.\n",
    "\n",
    "- Los valores más cercanos a 0 indican una baja probabilidad de $ H_1 | H_0 $\n",
    "- Los valores más cercanos a 1 indican una alta probabilidad de $ H_1 | H_0 $\n",
    "\n",
    "\n",
    "Un hallazgo se denomina `estadísticamente significativo` si el estadístico de prueba es mayor que un umbral.\n",
    "\n",
    "Eso es si $p(H_1) < p(\\alpha)$\n",
    "El umbral es arbitrario, los valores comunes son $p = 0.5$ o $p = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.axvline(1.6, label = '$\\\\alpha$', color = 'g', alpha = 0.7)\n",
    "ax.axvline(1.8, label = '$H_1$', color = 'r', alpha = 0.7)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.axvline(1.6, label = '$\\\\alpha$', color = 'g', alpha = 0.7)\n",
    "ax.axvline(0.6, label = '$H_1$', color = 'r', alpha = 0.7)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada lado de la distribución $H_0$ es poco probable.\n",
    "\n",
    "El umbral del valor p se refiere a toda el área de significancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "alpha = 0.05\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.axvline(h0.ppf(1 - alpha), label = '$\\\\alpha$', color = 'r', alpha = 0.7)\n",
    "ax.fill_between(x, h0.pdf(x), where = (x >= h0.ppf(1 - alpha)), alpha = 0.3, color = 'r')\n",
    "ax.legend(prop={'size': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cosa importante que hay que tener en cuenta es que si nosotros no establecemos un nivel de significancia $\\alpha$ entonces:\n",
    "\n",
    "- Aceptamos $H_0$ si el p-valor es \"grande\" ($\\geq 0.1$)\n",
    "- Rechazamos $H_0$ si el p-valor es \"pequeño\" ($\\leq 0.05$)\n",
    "    - El p-valor es _significativo_ si es $ < 0.05$\n",
    "    - El p-valor es _fuertemente significativo_ si es $ < 0.01$\n",
    "    - El p-valor es _Muy significativo_ si es $ < 0.001$\n",
    "    \n",
    "    \n",
    "Pero si el p-valor esta entre 0.05 y 0.1, entonces se requerirán estudios posteriores, es lo que se denomina la _zona crepuscular_ o _twilinght zone_. Es decir no podemos concluir si podemos rechazar o no $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Tipos de Hipótesis Alternativas\n",
    "\n",
    "\n",
    "Al momento de realizar una prueba de hipótesis lo vamos a representar de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "H_0 & \\text{Hipótesis nula}\\\\\n",
    "H_1 & \\text{Hipótesis alternativa}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Hay que generar una regla de decisión para poder rechazar o no la hipótesis nula partir de la información que contenga la muestra. Tengan en cuenta que es imposible encontrar evidencias de que un parámetro $\\mu$ sea igual a cierto valor $\\mu_0$, pero si podemos encontrar evidencia de que $\\mu < \\mu_0$, $\\mu > \\mu_0$ o $\\mu \\neq \\mu_0$, sabiendo esto la hipótesis alternativa y nula se caracterizaran por lo siguiente:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{llll}\n",
    "H_0: & = & \\leq & \\geq\\\\\n",
    "H_1: & < & > & \\neq\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "por ejemplo si queremos decidir si la media es más pequeña que 2 o no.\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "H_0: & \\mu = 2\\\\\n",
    "H_1: & \\mu < 2\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "si queremos decidir si la media es igual o diferente de 5:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "H_0: & \\mu = 5\\\\\n",
    "H_1: & \\mu \\neq 5\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "Esto nos provoca que haya dos tipos de pruebas, las pruebas unilaterales: Donde $H_1: \\mu < \\mu_0$ o $H_1: \\mu > \\mu_0$, o las pruebas bilaterales: $H_1: \\mu \\neq \\mu_0$. El test toma el nombre de las hipótesis alternativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "H_0: & \\mu = \\mu_0\\\\\n",
    "H_1: & \\mu < \\mu_0\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "h1 = stats.norm(-2.3, 1)\n",
    "x = np.linspace(-8, 5, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.plot(x, h1.pdf(x), label = '$H_1$')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "alpha = 0.05\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.axvline(h0.ppf(alpha), label = '$\\\\alpha$', color = 'r', alpha = 0.7)\n",
    "ax.fill_between(x, h0.pdf(x), where = (x <= h0.ppf(alpha)), alpha = 0.3, color = 'r')\n",
    "ax.legend(prop = {'size': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "H_0: & \\mu = \\mu_0\\\\\n",
    "H_1: & \\mu > \\mu_0\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "h1 = stats.norm(2.3, 1)\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.plot(x, h1.pdf(x), label = '$H_1$')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "alpha = 0.05\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.axvline(h0.ppf(1 - alpha), label = '$\\\\alpha$', color = 'r', alpha = 0.7)\n",
    "ax.fill_between(x, h0.pdf(x), where = (x >= h0.ppf(1 - alpha)), alpha = 0.3, color = 'r')\n",
    "ax.legend(prop={'size': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "H_0: & \\mu = \\mu_0\\\\\n",
    "H_1: & \\mu \\ne \\mu_0\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "h1 = stats.norm(2.3, 1)\n",
    "h2 = stats.norm(-2.3, 1)\n",
    "x = np.linspace(-8, 8, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.plot(x, h1.pdf(x), label = '$H_1$?')\n",
    "ax.plot(x, h2.pdf(x), label = '$H_1$?')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = stats.norm()\n",
    "x = np.linspace(-5, 8, 1000)\n",
    "alpha = 0.05\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, h0.pdf(x), label = '$H_0$')\n",
    "ax.axvline(h0.ppf(1 - alpha / 2), label = '$\\\\frac{\\\\alpha}{2}$', color = 'r', alpha = 0.7)\n",
    "ax.axvline(h0.ppf(alpha / 2), label = '$\\\\frac{\\\\alpha}{2}$', color = 'r', alpha = 0.7)\n",
    "ax.fill_between(x, h0.pdf(x), where = (x >= h0.ppf(1 - alpha / 2)), alpha = 0.3, color = 'r')\n",
    "ax.fill_between(x, h0.pdf(x), where = (x <= h0.ppf(alpha / 2)), alpha = 0.3, color = 'r')\n",
    "ax.legend(prop={'size': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de Errores\n",
    "\n",
    "\n",
    "Dado que podemos tomar una decisión con base a la muestra que estamos trabajando, y equivocarnos una prueba de hipótesis puede tener uno de los siguientes cuatro resultados:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|Decisión/Realidad|$H_0$ es verdadera|$H_0$ es falsa|\n",
    "|:---------------:|:----------------:|:------------:|\n",
    "|Fracasar en rechazar $H_0$|Decisión correcta de tipo A|Error de tipo II|\n",
    "|rechazar $H_0$|Error de tipo I|Decisión correcta de tipo B|\n",
    "\n",
    "\n",
    "\n",
    "<img src = 'https://www.statisticssolutions.com/wp-content/uploads/2017/12/rachnovblog.jpg'  > \n",
    "\n",
    "\n",
    "La decisión correcta de tipo A y B son _fracasar en rechazar $H_0$ cuando $H_0$ es verdadera_ y _rechazar $H_0$ cuando $H_0$ es falsa_. Ahora, no siempre se puede tomar la decisión correcta, por lo que existen los errores de tipo I y II, el error de tipo I es un _falso positivo_ (recordemos que el objetivo del investigador es rechazar $H_0$), es decir, este error se comete cuando e rechaza $H_0$ siendo esta verdadera, el error de tipo I tiene asociado una probabilidad de que ocurra que denotamos $\\alpha$ y es denominada significancia de la prueba. Por su parte el error de tipo II es un _falso negativo_ y ocurre cuando no se rechaza $H_0$ siendo esta falsa, la probabilidad de que cometamos un error de tipo II la denotamos por $\\beta$.\n",
    "\n",
    "Para encontrar estos errores se asigna una pequeña probabilidad a cada una de ellas, las probabilidades más comúnmente usadas para $\\alpha$ y $\\beta$ son 0.01 y 0.05. Por su lado las dos decisiones correctas tienen también sus propias probabilidades, para la decisión correcta de tipo A la probabilidad es $1-\\alpha$ y para la decisión correcta de tipo B es $1 - \\beta$. A la probabilidad $1 - \\beta$ se le llamada _potencia de la prueba_ porque es la medida de la capacidad de la prueba de rechazar una hipótesis nula falsa.\n",
    "\n",
    "$$P(\\text{Error tipo I}) = P(\\text{Rechazar} H_0|H_0 \\text{es cierta}) = \\alpha$$\n",
    "\n",
    "$$P(\\text{Error tipo II}) = P(\\text{Aceptar} H_0|H_0 \\text{es falsa}) = \\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(alpha, h1_mean):\n",
    "    \n",
    "    h0 = stats.norm()\n",
    "    h1 = stats.norm(h1_mean, 1)\n",
    "    x = np.linspace(-5, 8, 1000)\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (13, 8))\n",
    "\n",
    "\n",
    "    ax[0, 0].plot(x, h0.pdf(x), label = '$H_0$')\n",
    "    ax[0, 0].plot(x, h1.pdf(x), label = '$H_1$')\n",
    "    ax[0, 0].axvline(h0.ppf(1 - alpha), label = 'significance threshold ($\\\\alpha$)', color = 'r', alpha = 0.7)\n",
    "    ax[0, 0].fill_between(x, h0.pdf(x), where = (x <= h0.ppf(1 - alpha)), alpha = 0.7, color = 'skyblue')\n",
    "    ax[0, 0].set_title('True Negative')\n",
    "\n",
    "    ax[0, 1].plot(x, h0.pdf(x), label = '$H_0$')\n",
    "    ax[0, 1].plot(x, h1.pdf(x), label = '$H_1$')\n",
    "    ax[0, 1].axvline(h0.ppf(1 - alpha), label = 'significance threshold ($\\\\alpha$)', color = 'r', alpha = 0.7)\n",
    "    ax[0, 1].fill_between(x, h1.pdf(x), where = (x <= h0.ppf(1 - alpha)), alpha = 0.3, color = 'red')\n",
    "    ax[0, 1].set_title('False Negative')\n",
    "\n",
    "    ax[1, 0].plot(x, h0.pdf(x), label = '$H_0$')\n",
    "    ax[1, 0].plot(x, h1.pdf(x), label = '$H_1$')\n",
    "    ax[1, 0].axvline(h0.ppf(1 - alpha), label = 'significance threshold ($\\\\alpha$)', color = 'r', alpha = 0.7)\n",
    "    ax[1, 0].fill_between(x, h0.pdf(x), where = (x >= h0.ppf(1 - alpha)), alpha = 0.3, color = 'red')\n",
    "    ax[1, 0].set_title('False Positive')\n",
    "\n",
    "    ax[1, 1].plot(x, h0.pdf(x), label = '$H_0$')\n",
    "    ax[1, 1].plot(x, h1.pdf(x), label = '$H_1$')\n",
    "    ax[1, 1].axvline(h0.ppf(1 - alpha), label = 'significance threshold ($\\\\alpha$)', color = 'r', alpha = 0.7)\n",
    "    ax[1, 1].fill_between(x, h1.pdf(x), where = (x >= h0.ppf(1 - alpha)), alpha = 0.7, color = 'skyblue')\n",
    "    ax[1, 1].set_title('True Positive');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(error_plot, alpha = (0.01, 0.5, 0.01), h1_mean = (2, 7, 0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba paramétrica vs no paramétrica\n",
    "\n",
    "Qué no significa `no paramétrico`:\n",
    "\n",
    "- ** Sin parámetros en absoluto **\n",
    "\n",
    "Significado correcto:\n",
    "\n",
    "- Estadísticas que no se basan en supuestos sobre la distribución subyacente.\n",
    "- Métodos de inferencia estadística que generan la distribución $H_0$ a partir de los datos, no de una ecuación.\n",
    "\n",
    "| Prueba paramétrica | Prueba no paramétrica |\n",
    "|: -------------: |: -----------------: |\n",
    "| T-test de 1 muestra | Prueba de rangos singulares de Wilcoxon |\n",
    "| T-test t de 2 muestras | Prueba U de Mann-Whitney |\n",
    "| Correlación de Pearson | Correlación de Sperman |\n",
    "\n",
    "\n",
    "\n",
    "** Ventajas y limitaciones **\n",
    "\n",
    "| Prueba paramétrica | Prueba no paramétrica |\n",
    "|: -------------: |: -----------------: |\n",
    "| Estándar, ampliamente utilizado | Algunos no son estándar |\n",
    "| Basado en supuestos | No basado en supuestos |\n",
    "| Las suposiciones deben probarse | Puede ser lento |\n",
    "| Puede ser incorrecto cuando se violan las suposiciones | Apropiado para datos no numéricos |\n",
    "| Computacionalmente rápido | Apropiado para tamaños de muestra pequeños |\n",
    "|| Algunos métodos dan resultados diferentes cada vez |\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Utilice métodos paramétricos cuando sea posible, y utilice métodos no paramétricos cuando sea necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlación\n",
    "\n",
    "En el sentido más amplio, la correlación es cualquier asociación estadística, aunque comúnmente se refiere al grado en que un par de variables están relacionadas linealmente.\n",
    "\n",
    "- Un análisis de correlación calcula un coeficiente de correlación.\n",
    "\n",
    "- el coeficiente de correlación es un número único que muestra la relación entre dos variables.\n",
    "\n",
    "- El coeficiente de correlación varía entre -1 y 1.\n",
    "\n",
    "    - -1 significa una relación inversa perfecta.\n",
    "    - 0 significa que no hay relación\n",
    "    - 1 significa una relación positiva perfecta.\n",
    "\n",
    "- El coeficiente de correlación en sí mismo es una medida continua de la fuerza de la correlación. Se debe calcular un valor p correspondiente para interpretar su significación estadística.\n",
    "\n",
    "<img src = 'https://upload.wikimedia.org/wikipedia/commons/d/d4/Correlation_examples2.svg'>\n",
    "\n",
    "\n",
    "\n",
    "## Correlación vs causalidad\n",
    "\n",
    "- La correlación simplemente muestra una relación.\n",
    "- No revela ni implica causalidad.\n",
    "- La causalidad puede demostrarse mediante manipulaciones experimentales.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "- Helado → Ataques de tiburones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Covarianza y correlación: fórmulas\n",
    "\n",
    "¿Cuál es la diferencia entre covarianza y correlación ?:\n",
    "\n",
    "- La covarianza es un número único que mide la relación lineal entre dos variables.\n",
    "- La covarianza está en la misma escala que los datos originales.\n",
    "- La correlación es la covarianza escalada.\n",
    "- Es independiente de la escala de datos.\n",
    "\n",
    "**Covarianza**\n",
    "\n",
    "$$cov[X, Y] = \\frac{1}{n - 1} \\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "\n",
    "**Correlación**\n",
    "\n",
    "$$r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$$\n",
    "\n",
    "\n",
    "**P-valor**\n",
    "\n",
    "$$t_{n-2} = \\frac{r \\sqrt{n - 2}}{1 - r^2}$$\n",
    "\n",
    "- La significancia estadística se calcula a partir de un valor t que se basa en la fuerza de la correlación y el número de puntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = pd.read_csv('high_diamond_ranked_10min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = lol['blueTotalGold'].values\n",
    "exp  = lol['blueTotalExperience'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "ax.scatter(gold, exp, color = 'skyblue', marker = 'p')\n",
    "ax.set_xlabel('Gold of the team')\n",
    "ax.set_ylabel('Experience of the team');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dprocessing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lol[['blueTotalGold', 'blueTotalExperience']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = dp.Outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = outliers.fit(data = data, how = 'zscore', verbose = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_gold = clean_data['blueTotalGold']\n",
    "clean_exp  = clean_data['blueTotalExperience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (13, 8))\n",
    "\n",
    "ax[0].scatter(gold, exp, color = 'r', marker = 'p', alpha = 0.7)\n",
    "ax[0].set_xlabel('Gold of the team')\n",
    "ax[0].set_ylabel('Experience of the team')\n",
    "ax[0].set_xlim([10_000, 25_000])\n",
    "ax[0].set_ylim([10_000, 23_000])\n",
    "\n",
    "\n",
    "ax[1].scatter(clean_gold, clean_exp, color = 'skyblue', marker = 'p')\n",
    "ax[1].set_xlabel('Gold of the team')\n",
    "ax[1].set_ylabel('Experience of the team')\n",
    "ax[1].set_xlim([10_000, 25_000])\n",
    "ax[1].set_ylim([10_000, 23_000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(clean_gold, clean_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(clean_gold, clean_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(clean_gold[::100], clean_exp[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## El problema con Pearson\n",
    "\n",
    "<img src = 'https://www.researchgate.net/profile/Andrew-Heathcote/publication/280302159/figure/fig2/AS:614021682171910@1523405585885/Anscombes-quartet-highlights-the-importance-of-plotting-data-to-confirm-the-validity-of.png'>\n",
    "\n",
    "\n",
    "- La correlación de Pearson puede representar de forma excesiva o insuficiente las relaciones si contienen no linealidades o valores atípicos.\n",
    "\n",
    "- Pearson es apropiado para datos distribuidos normalmente.\n",
    "\n",
    "\n",
    "\n",
    "### Correlación de Spearman\n",
    "\n",
    "Este es el método dominante para las correlaciones no paramétricas y es una alternativa para la correlación de Pearson.\n",
    "\n",
    "- Pearson y Spearman convergen cuando los datos se distribuyen normalmente.\n",
    "\n",
    "\n",
    "La $\\rho$ de Spearman busca una una relación monótona, independientemente de si la relación es lineal o no lineal.\n",
    "\n",
    "\n",
    "- Para calcular $\\rho$, los datos son ordenados y reemplazados por su respectivo orden.\n",
    "\n",
    "    - $ [3321654, -40, 1, 0] a [4, 1, 3, 2] $\n",
    "    \n",
    "- Calcular el coeficiente de correlación de Pearson en rangos.\n",
    "\n",
    "- Mismo valor p para Pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(clean_gold, clean_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anscobe's quartet\n",
    "\n",
    "anscombe = np.array([\n",
    "     # series 1     series 2      series 3       series 4\n",
    "    [10,  8.04,    10,  9.14,    10,  7.46,      8,  6.58, ],\n",
    "    [ 8,  6.95,     8,  8.14,     8,  6.77,      8,  5.76, ],\n",
    "    [13,  7.58,    13,  8.76,    13, 12.74,      8,  7.71, ],\n",
    "    [ 9,  8.81,     9,  8.77,     9,  7.11,      8,  8.84, ],\n",
    "    [11,  8.33,    11,  9.26,    11,  7.81,      8,  8.47, ],\n",
    "    [14,  9.96,    14,  8.10,    14,  8.84,      8,  7.04, ],\n",
    "    [ 6,  7.24,     6,  6.13,     6,  6.08,      8,  5.25, ],\n",
    "    [ 4,  4.26,     4,  3.10,     4,  5.39,      8,  5.56, ],\n",
    "    [12, 10.84,    12,  9.13,    12,  8.15,      8,  7.91, ],\n",
    "    [ 7,  4.82,     7,  7.26,     7,  6.42,      8,  6.89, ],\n",
    "    [ 5,  5.68,     5,  4.74,     5,  5.73,     19, 12.50, ]\n",
    "    ])\n",
    "\n",
    "\n",
    "# plot and compute correlations\n",
    "fig, ax = plt.subplots(2, 2, figsize =(13, 8))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].plot(anscombe[:, 2 * i],anscombe[:, (2 * i) + 1],'ko')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    corr_p = stats.pearsonr(anscombe[:, 2 * i],anscombe[:, (2 * i) + 1])[0]\n",
    "    corr_s = stats.spearmanr(anscombe[:, 2 * i],anscombe[:, (2 * i) + 1])[0]\n",
    "    ax[i].set_title('$r_p$ = {} | $r_s$ = {}'.format(np.round(corr_p, 2),np.round(corr_s, 2)), fontsize = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# T-test\n",
    "\n",
    "## Propósito e interpretación de la prueba t\n",
    "\n",
    "La prueba T es una de las estadísticas más importantes y más utilizadas. La idea principal de la prueba t es comparar los valores (normalmente la media) entre dos grupos.\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "H_0 & \\mu_1 = \\mu_2\\\\\n",
    "H_1 & \\mu_1 \\ne \\mu_2\\\\\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "La fórmula general del t-test es la siguiente:\n",
    "\n",
    "$$t_k = \\frac{\\bar{x} - \\bar{y}}{\\frac{s}{\\sqrt{n}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def studend_vs_gauss(n):\n",
    "    \n",
    "    #distribution\n",
    "    gauss   = stats.norm()\n",
    "    student = stats.t(n)\n",
    "    \n",
    "    x = np.linspace(-3, 3, 1000)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (13, 8))\n",
    "    \n",
    "    ax.plot(x, gauss.pdf(x), label = 'Normal Distribution')\n",
    "    ax.plot(x, student.pdf(x), color = 'r', label = \"Student's t-Distribution {}\".format(n))\n",
    "    ax.set_title('Gauss vs Student distribution')\n",
    "    ax.legend(prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(studend_vs_gauss, n = (1, 50, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test de una muestra\n",
    "\n",
    "Pruebe si se pudo haber extraído un conjunto de números de una distribución con una media especificada.\n",
    "\n",
    "\n",
    "- Probar si el coeficiente intelectual de un grupo de estudiantes es significativamente diferente de 100.\n",
    "\n",
    "$$t_{n - 1} = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$$\n",
    "\n",
    "\n",
    "- $\\bar{x}$ → media muestral\n",
    "- $\\mu$ → valor de $H_0$ \n",
    "- $s$ → desviasión estandar muestral\n",
    "- $n$ → Número de puntos\n",
    "- $n - 1$ → grados de libertad\n",
    "\n",
    "### T-test de una muestra: supuestos\n",
    "\n",
    "1. Los datos son numéricos (no categóricos).\n",
    "2. Los datos son independientes entre sí.\n",
    "3. Los datos se extraen aleatoriamente de la población a la que se debe hacer una generalización.\n",
    "4. La media y la desviación estándar son medidas válidas de tendencia central y dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data = pd.read_csv('Islander_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data['Drug'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data['Happy_Sad_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data['Dosage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = {d : drug_data[(drug_data['Drug'] == d) & (drug_data['Happy_Sad_group'] == 'H')] for d in drug_data['Drug'].unique()}\n",
    "sad   = {d : drug_data[(drug_data['Drug'] == d) & (drug_data['Happy_Sad_group'] == 'S')] for d in drug_data['Drug'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in happy.keys():\n",
    "    happy[k] = {d : happy[k][(happy[k]['Dosage'] == d)] for d in happy[k]['Dosage'].unique()}\n",
    "    sad[k]   = {d : sad[k][(sad[k]['Dosage'] == d)] for d in sad[k]['Dosage'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Happy {} dosage {} group: {} | Sad {} dosage {} group: {}'\n",
    "for k1 in happy.keys():\n",
    "    for k2 in happy[k].keys():\n",
    "        print(message.format(k1, k2, happy[k1][k2].shape[0], k1, k2, sad[k1][k2].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy['A'][2]['Diff'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "H_0 & \\mu = 0\\\\\n",
    "H_1 & \\mu \\ne 0\\\\\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"manual\" t-test\n",
    "\n",
    "# the null-hypothesis value\n",
    "mu = 0\n",
    "\n",
    "# compute the t-value\n",
    "t_happy = (happy['S'][2]['Diff'].mean() - mu) / (happy['S'][2]['Diff'].std() / np.sqrt(happy['S'][2].shape[0]))\n",
    "t_sad   = (sad['S'][2]['Diff'].mean() - mu) / (sad['S'][2]['Diff'].std() / np.sqrt(sad['S'][2].shape[0]))\n",
    "\n",
    "# degrees of freedom\n",
    "df_happy = happy['S'][2].shape[0] - 1\n",
    "df_sad   = sad['S'][2].shape[0] - 1\n",
    "\n",
    "\n",
    "#distributions\n",
    "dist_happy = stats.t(df_happy)\n",
    "dist_sad   = stats.t(df_sad)\n",
    "\n",
    "# p-value\n",
    "pval_happy = 1 - dist_happy.cdf(abs(t_happy))\n",
    "pval_sad   = 1 - dist_sad.cdf(abs(t_sad))\n",
    "\n",
    "\n",
    "# show the H0 parameter distribution and observed t-value\n",
    "x = np.linspace(-4, 4, 1001)\n",
    "fig, ax = plt.subplots(1, 2, figsize = (13, 8))\n",
    "\n",
    "ax[0].plot(x, dist_happy.pdf(x), label = 'Happy memories')\n",
    "ax[0].axvline(t_happy, color = 'k', alpha = 0.7)\n",
    "ax[0].set_xlabel('t-value')\n",
    "ax[0].set_ylabel('pdf(t)')\n",
    "ax[0].set_title('t({}) = {}, p = {}'.format(df_happy, np.round(t_happy, 2), np.round(pval_happy, 2)))\n",
    "ax[0].legend(prop={'size': 15})\n",
    "\n",
    "ax[1].plot(x, dist_sad.pdf(x), label = 'Sad memories')\n",
    "ax[1].axvline(t_sad, color = 'k', alpha = 0.7)\n",
    "ax[1].set_xlabel('t-value')\n",
    "ax[1].set_ylabel('pdf(t)')\n",
    "ax[1].set_title('t({}) = {}, p = {}'.format(df_sad, np.round(t_sad, 2), np.round(pval_sad, 2)))\n",
    "ax[1].legend(prop={'size': 15});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"manual\" t-test\n",
    "\n",
    "# the null-hypothesis value\n",
    "mu = 0\n",
    "\n",
    "# compute the t-value\n",
    "t_happy = (happy['A'][2]['Diff'].mean() - mu) / (happy['A'][2]['Diff'].std(ddof = 1) / np.sqrt(happy['A'][2].shape[0]))\n",
    "t_sad   = (sad['A'][2]['Diff'].mean() - mu) / (sad['A'][2]['Diff'].std(ddof = 1) / np.sqrt(sad['A'][2].shape[0]))\n",
    "\n",
    "# degrees of freedom\n",
    "df_happy = happy['A'][2].shape[0] - 1\n",
    "df_sad   = sad['A'][2].shape[0] - 1\n",
    "\n",
    "\n",
    "#distributions\n",
    "dist_happy = stats.t(df_happy)\n",
    "dist_sad   = stats.t(df_sad)\n",
    "\n",
    "# p-value\n",
    "pval_happy = 1 - dist_happy.cdf(abs(t_happy))\n",
    "pval_sad   = 1 - dist_sad.cdf(abs(t_sad))\n",
    "\n",
    "\n",
    "# show the H0 parameter distribution and observed t-value\n",
    "x = np.linspace(-4, 4, 1001)\n",
    "fig, ax = plt.subplots(1, 2, figsize = (13, 8))\n",
    "\n",
    "ax[0].plot(x, dist_happy.pdf(x), label = 'Happy memories')\n",
    "ax[0].axvline(t_happy, color = 'k', alpha = 0.7)\n",
    "ax[0].set_xlabel('t-value')\n",
    "ax[0].set_ylabel('pdf(t)')\n",
    "ax[0].set_title('t({}) = {}, p = {}'.format(df_happy, np.round(t_happy, 4), np.round(pval_happy, 4)))\n",
    "ax[0].legend(prop={'size': 15})\n",
    "\n",
    "ax[1].plot(x, dist_sad.pdf(x), label = 'Sad memories')\n",
    "ax[1].axvline(t_sad, color = 'k', alpha = 0.7)\n",
    "ax[1].set_xlabel('t-value')\n",
    "ax[1].set_ylabel('pdf(t)')\n",
    "ax[1].set_title('t({}) = {}, p = {}'.format(df_sad, np.round(t_sad, 4), np.round(pval_sad, 4)))\n",
    "ax[1].legend(prop={'size': 15});\n",
    "\n",
    "pval_happy, pval_sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(happy['A'][2]['Diff'], mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sad['A'][2]['Diff'], mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_1samp(happy['A'][2]['Diff'], mu)\n",
    "\n",
    "p, pval_happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-test de dos muestras\n",
    "\n",
    "Pruebe si se podrían haber extraído dos conjuntos de números de la misma distribución.\n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "- Pruebe si los niveles de estrés autoinformados cambian después de 6 semanas de 'distanciamiento social'.\n",
    "\n",
    "(Declaraciones formales: Estime la probabilidad de que los niveles de estrés autoinformados antes y después de 6 semanas de distanciamiento social se extraigan de la misma distribución).\n",
    "\n",
    "Hay varias fórmulas de prueba t de dos muestras. El numerador es siempre el mismo, pero el denominador depende de si los grupos están emparejados o no emparejados, tienen una varianza igual o desigual y tienen tamaños de muestra emparejados o diferentes.\n",
    "\n",
    "- Emparejado o no emparejado: si los dos grupos de datos provienen del mismo o de diferentes individuos.\n",
    "\n",
    "    - Emparejado: Los mismos individuos autoinforman sus niveles de estrés antes y después del distanciamiento social.\n",
    "    - No emparejado: cambio en el estrés relacionado con el distanciamiento social en Dinamarca frente a Singapur.\n",
    "\n",
    "- Varianza igual o desigual: si los dos grupos tienen (aproximadamente) la misma varianza.\n",
    "\n",
    "    - Igualdad de varianza: los grupos 'A' y 'B' son estudiantes caucásicos de 20 años de la misma universidad; El grupo 'A' estudia ingeniería y el grupo 'B' estudia informática.\n",
    "    - Varianza desigual: el grupo 'A' son estudiantes caucásicos de 20 años de la misma universidad de ingeniería, el grupo 'B' es una muestra aleatoria de 20 años de todo el país.\n",
    "\n",
    "- Tamaños de muestra iguales o desiguales: si los grupos tienen el mismo número de valores (se aplica solo a grupos no apareados).\n",
    "\n",
    "$$t_{df} = \\frac{\\bar{x} - \\bar{y}}{\\sqrt{\\frac{(n_1 - 1)s_{1}^{2} + (n_2 - 1)s_{2}^{2}}{n_1 + n_2 - 2}} \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparar el tiempo medio de diferencia en los pacientes que recibieron placebo y la droga 'T'\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "H_0 & \\mu_1 = \\mu_2\\\\\n",
    "H_1 & \\mu_1 \\ne \\mu_2\\\\\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(happy['T'][1]['Diff'], happy['S'][1]['Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Happy group Droge T vs S Dosage: {}| p-value: {}\\nSad group Droge T vs S Dosage: {}  | p-value: {}'\n",
    "\n",
    "for k in happy['T'].keys():\n",
    "    t_h, p_h = stats.ttest_ind(happy['T'][k]['Diff'], happy['S'][k]['Diff'], equal_var = True)\n",
    "    t_s, p_s = stats.ttest_ind(sad['T'][k]['Diff'], sad['S'][k]['Diff'], equal_var = True)\n",
    "    \n",
    "    print(message.format(k, p_h, k, p_s))\n",
    "    print()\n",
    "    print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Happy group Droge A vs S Dosage: {}| p-value: {}\\nSad group Droge A vs S Dosage: {}  | p-value: {}'\n",
    "\n",
    "for k in happy['T'].keys():\n",
    "    t_h, p_h = stats.ttest_ind(happy['A'][k]['Diff'], happy['S'][k]['Diff'], equal_var = True)\n",
    "    t_s, p_s = stats.ttest_ind(sad['A'][k]['Diff'], sad['S'][k]['Diff'], equal_var = True)\n",
    "    \n",
    "    print(message.format(k, p_h, k, p_s))\n",
    "    print()\n",
    "    print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilcoxon signed-rank (T-test no paramétrico)\n",
    "\n",
    "\n",
    "Alternativa no paramétrica al T-test de una o dos muestras.\n",
    "\n",
    "- Se utiliza principalmente cuando los datos no se ajustan al supuesto de normalidad.\n",
    "\n",
    "- Pruebe las diferencias en las medianas en lugar de las diferencias en las medias (la mediana es insensible a los valores atípicos)\n",
    "\n",
    "\n",
    "| Nombre de la prueba | Cuándo usar |\n",
    "|: -------: |: ---------: |\n",
    "| Wilcoxon signed-rank | Una muestra |\n",
    "| Signed-rank | Dos muestras emparejadas |\n",
    "| U-test de Mann-Whitney | Dos muestras independientes |\n",
    "| U-test de Mann-Whitney-Wilcoxon | Dos muestras independientes |\n",
    "| Wilcoxon rank-sum test | Dos muestras independientes |\n",
    "\n",
    "\n",
    "1. Eliminar pares iguales (eliminar pares iguales de puntos de datos que igualen el valor $H_0$)\n",
    "    - ¿Por qué? Los pares iguales no contribuyen a la prueba de ninguna manera.\n",
    "2. Transforma a ranking las direrencias\n",
    "    - $r = rank(|x - y|)$\n",
    "    \n",
    "\n",
    "3. Suma ranking donde $x > y$\n",
    "    - $W = \\sum (r \\times (x > y))$\n",
    "    \n",
    "    \n",
    "4. Convertir a z\n",
    "\n",
    "$$Z = \\frac{W - \\frac{n(n + 1)}{4}}{\\sqrt{\\frac{n(n + 1)(2n + 1)}{24}}}$$\n",
    "\n",
    "\n",
    "\n",
    "- $n$ Es el número de pares restantes.\n",
    "- $Z$ esta normalmente distribuida bajo $H_0$ y se le puede obtener un p-valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(happy['A'][3]['Mem_Score_Before'], happy['A'][3]['Mem_Score_After'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(happy['S'][2]['Diff'] - 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de Confianza\n",
    "\n",
    "## ¿Qué son los intervalos de confianza y por qué los necesitamos?\n",
    "\n",
    "Imagina que hacemos los siguientes estudios:\n",
    "\n",
    "- Estudio 1: Mida la altura en 10 personas seleccionadas al azar, calcule el promedio. Repite 500 veces.\n",
    "- Estudio 2: Medir la altura en 80 personas seleccionadas al azar, calcular el promedio. Repite 500 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate the population\n",
    "dist = stats.norm(1.84, 0.17)\n",
    "\n",
    "population = dist.rvs(1_582_299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesize1   = 10\n",
    "samplesize2   = 80\n",
    "numberOfExps  = 500\n",
    "\n",
    "samplemeans1  = np.zeros(numberOfExps)\n",
    "samplemeans2  = np.zeros(numberOfExps)\n",
    "\n",
    "for i in range(numberOfExps):\n",
    "    # get a sample and compute its mean\n",
    "    samplemeans1[i] = np.mean(np.random.choice(population, samplesize1))\n",
    "    samplemeans2[i] = np.mean(np.random.choice(population, samplesize2))\n",
    "\n",
    "    \n",
    "gauss1 = stats.norm(samplemeans1.mean(), samplemeans1.std())\n",
    "gauss2 = stats.norm(samplemeans2.mean(), samplemeans2.std())\n",
    "\n",
    "x = np.linspace(1.60, 2.10, 1000)\n",
    "# and show its distribution\n",
    "\n",
    "\n",
    "# show the distribution\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "ax.hist(samplemeans1, color = [127 / 255, 255 / 255, 0 / 255, 0.5], density = True, bins = 40, label = 'Sample: 10');\n",
    "ax.plot(x, gauss1.pdf(x), color = 'r')\n",
    "ax.axvline(samplemeans1.mean(), c = 'r', alpha = 0.7)\n",
    "ax.hist(samplemeans2, color = [153 / 255, 50 / 255, 204 / 255, 0.5], density = True, bins = 40, label = 'Sample: 80');\n",
    "ax.plot(x, gauss2.pdf(x), color = 'b')\n",
    "ax.axvline(samplemeans2.mean(), c = 'b', alpha = 0.7)\n",
    "ax.set_xlabel('Mean estimate', fontsize = 15)\n",
    "ax.set_ylabel('Count', fontsize = 15)\n",
    "ax.legend(prop = {'size' : 15});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Illegal die\n",
    "probabilities = np.array([1/4, 1/4, 1/8, 1/8, 1/8, 1/8])\n",
    "values        = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "\n",
    "E = (values * probabilities).sum()\n",
    "\n",
    "population = np.random.choice(values, size = 1_000_000, p = probabilities)\n",
    "\n",
    "## experiment: draw larger and larger samples\n",
    "\n",
    "k = 5000  # maximum number of samples\n",
    "sampleAve = np.zeros(k)\n",
    "\n",
    "for i in range(k):\n",
    "    sample = np.random.choice(population, size = i + 1) \n",
    "    sampleAve[i] = np.mean(sample)\n",
    "\n",
    "\n",
    "    \n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "ax.plot(sampleAve, 'k', label = 'Sample average')\n",
    "ax.axhline(E, color = 'r', alpha = 0.7, linewidth = 4, label = 'expected value')\n",
    "ax.set_xlabel('Number of samples', fontsize = 15)\n",
    "ax.set_ylabel('Value', fontsize = 15)\n",
    "ax.set_ylim([E - 1, E + 1])\n",
    "ax.legend()\n",
    "\n",
    "# mean of samples converges to population estimate quickly:\n",
    "print( np.mean(sampleAve) )\n",
    "print( np.mean(sampleAve[:9]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate the population\n",
    "dist = stats.norm(1.84, 0.17)\n",
    "\n",
    "population = dist.rvs(1_582_299)\n",
    "\n",
    "samplesize1   = 10\n",
    "samplesize2   = 80\n",
    "numberOfExps  = 500\n",
    "\n",
    "samplemeans1  = np.zeros(numberOfExps)\n",
    "samplemeans2  = np.zeros(numberOfExps)\n",
    "\n",
    "for i in range(numberOfExps):\n",
    "    # get a sample and compute its mean\n",
    "    samplemeans1[i] = np.mean(np.random.choice(population, samplesize1))\n",
    "    samplemeans2[i] = np.mean(np.random.choice(population, samplesize2))\n",
    "\n",
    "    \n",
    "gauss1 = stats.norm(samplemeans1.mean(), samplemeans1.std())\n",
    "gauss2 = stats.norm(samplemeans2.mean(), samplemeans2.std())\n",
    "\n",
    "x = np.linspace(1.60, 2.10, 1000)\n",
    "# and show its distribution\n",
    "\n",
    "\n",
    "# show the distribution\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "ax.hist(samplemeans1, color = [127 / 255, 255 / 255, 0 / 255, 0.5], density = True, bins = 40);\n",
    "ax.plot(x, gauss1.pdf(x), color = 'r')\n",
    "ax.plot([samplemeans1.mean() - 2 * samplemeans1.std(), samplemeans1.mean() + 2 * samplemeans1.std()], [5, 5], 'r--')\n",
    "ax.axvline(samplemeans1.mean(), c = 'r', alpha = 0.7)\n",
    "ax.hist(samplemeans2, color = [153 / 255, 50 / 255, 204 / 255, 0.5], density = True, bins = 40);\n",
    "ax.plot(x, gauss2.pdf(x), color = 'b')\n",
    "ax.plot([samplemeans2.mean() - 2 * samplemeans2.std(), samplemeans2.mean() + 2 * samplemeans2.std()], [15, 15], 'b--')\n",
    "ax.axvline(samplemeans2.mean(), c = 'b', alpha = 0.7)\n",
    "ax.set_xlabel('Mean estimate', fontsize = 15)\n",
    "ax.set_ylabel('Count', fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervalo de confianza: definición\n",
    "\n",
    "- Intervalo de confianza: rango de valores con cierta probabilidad de que un parámetro poblacional desconocido se encuentre dentro en repetidas muestras.\n",
    "\n",
    "$$P(L < \\mu < U) = c$$\n",
    "\n",
    "Probabilidades típicas del intervalo de confianza:\n",
    "\n",
    "- 95%\n",
    "- 99%\n",
    "- 90%\n",
    "\n",
    "\n",
    "Los intervalos de confianza están influenciados por el tamaño y la varianza de la muestra.\n",
    "\n",
    "- Cuando el tamaño de la muestra es mayor, los intervalos de confianza son más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular intervalos de confianza mediante fórmula.\n",
    "\n",
    "En la práctica, no podemos salir y repetir nuestro experimento 500 veces, generalmente solo tomamos una muestra (hacemos un experimento), por lo que necesitamos una forma de calcular los intervalos de confianza utilizando una sola muestra.\n",
    "\n",
    "$$CI: = \\bar{x} \\pm t^*(k)\\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "\n",
    "- $ bar {x} $ → media muestral.\n",
    "- $ t^* $ → valor t con k grados de libertad\n",
    "- $ s $ → desviación estándar de la muestra\n",
    "- $ n $ → tamaño de muestra\n",
    "\n",
    "\n",
    "$ t^* $: valor t asociado con una cola del intervalo de confianza:\n",
    "\n",
    "$$ t^* = tinv ( \\frac{(1 - c)}{2}, n - 1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence =  0.95\n",
    "\n",
    "dist = stats.t(20)\n",
    "\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "\n",
    "ax.plot(x, dist.pdf(x))\n",
    "ax.axvline(dist.ppf((1 - confidence) / 2), color = 'r', alpha = 0.7)\n",
    "ax.fill_between(x, dist.pdf(x), where = (x <= dist.ppf((1 - confidence) / 2)), alpha = 0.3, color = 'r')\n",
    "ax.axvline(dist.ppf(1 - ((1 - confidence) / 2)), color = 'r', alpha = 0.7)\n",
    "ax.fill_between(x, dist.pdf(x), where = (x >= dist.ppf(1 - ((1 - confidence) / 2))), alpha = 0.3, color = 'r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "popN = 10_000_000  # lots and LOTS of data!!\n",
    "\n",
    "# the data (note: non-normal!)\n",
    "population = (4 * np.random.randn(popN)) ** 2\n",
    "\n",
    "# we can calculate the exact population mean\n",
    "popMean = np.mean(population)\n",
    "\n",
    "# let's see it\n",
    "fig, ax = plt.subplots(2, 1, figsize = (13, 8))\n",
    "\n",
    "# only plot every 1000th sample\n",
    "ax[0].plot(population[::1000], 'k.')\n",
    "ax[0].set_xlabel('Data index')\n",
    "ax[0].set_ylabel('Data value')\n",
    "\n",
    "ax[1].hist(population, bins = 'fd') #Freedman Diaconis Estimator\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[1].set_xlabel('Data value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw a random sample\n",
    "\n",
    "# parameters\n",
    "samplesize = 40\n",
    "confidence = 0.95 \n",
    "\n",
    "# compute sample mean\n",
    "sample = np.random.choice(population, samplesize)\n",
    "samplemean  = np.mean(sample)\n",
    "samplestd   = np.std(sample, ddof = 1)\n",
    "\n",
    "# compute confidence intervals\n",
    "citmp = (1 - confidence) / 2\n",
    "confint = samplemean + stats.t.ppf([citmp, 1 - citmp], samplesize - 1) * (samplestd / np.sqrt(samplesize))\n",
    "print('Confidence interval computing with formula: {}'.format(confint))\n",
    "\n",
    "# graph everything\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "y = np.array([[confint[0], 0], [confint[1], 0], [confint[1], 1], [confint[0], 1]])\n",
    "p = Polygon(y, facecolor = 'g', alpha = 0.3, label = '{}% CI region'.format(confidence * 100))\n",
    "ax.add_patch(p)\n",
    "\n",
    "# now add the lines\n",
    "ax.plot([popMean, popMean], [0, 1.5], 'k:', linewidth = 2, label = 'True mean')\n",
    "ax.plot([samplemean, samplemean], [0, 1], 'r--', linewidth = 3, label = 'Sample mean')\n",
    "ax.set_xlim([popMean-30, popMean+30])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Data values')\n",
    "ax.legend(prop = {'size' : 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## repeat for large number of samples\n",
    "\n",
    "# parameters\n",
    "samplesize = 50\n",
    "confidence = 0.95\n",
    "numExperiments = 5000\n",
    "\n",
    "withinCI = np.zeros(numExperiments)\n",
    "\n",
    "\n",
    "# part of the CI computation can be done outside the loop\n",
    "citmp = (1 - confidence) / 2\n",
    "CI_T  = stats.t.ppf([citmp, 1 - citmp], samplesize - 1)\n",
    "sqrtN = np.sqrt(samplesize)\n",
    "\n",
    "for i in range(numExperiments):\n",
    "    \n",
    "    # compute sample mean and CI as above\n",
    "    sample = np.random.choice(population, samplesize)\n",
    "    samplemean  = np.mean(sample)\n",
    "    samplestd   = np.std(sample, ddof = 1)\n",
    "    confint     = samplemean + CI_T * (samplestd / sqrtN)\n",
    "    \n",
    "    # determine whether the True mean is inside this CI\n",
    "    if popMean > confint[0] and popMean < confint[1]:\n",
    "        withinCI[i] = 1\n",
    "        \n",
    "        \n",
    "\n",
    "print('{}% of sample C.I.s contained the true population mean.'.format(np.round(100 * np.mean(withinCI), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervalos de confianza mediante bootstrapping.\n",
    "\n",
    "En lugar de utilizar una fórmula para calcular los intervalos de confianza, calcúlelos directamente en función de los datos.\n",
    "Esto se hace volviendo a muestrear repetidamente al azar de su conjunto de datos. Por lo tanto, imagina que tu muestra es la población y que el remuestreo es la muestra.\n",
    "\n",
    "\n",
    "\n",
    "Ventajas:\n",
    "- Funciona para cualquier tipo de parámetro (media, varianza, correlación, mediana, etc.)\n",
    "- Útil para datos limitados (sin repeticiones de experimentos)\n",
    "- No basado en supuestos de normalidad.\n",
    "\n",
    "Limitaciones:\n",
    "- Da resultados (ligeramente) diferentes cada vez.\n",
    "- Puede llevar mucho tiempo para grandes conjuntos de datos.\n",
    "- La muestra debe ser una buena representación de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "popN = 10_000_000  # lots and LOTS of data!!\n",
    "\n",
    "# the data (note: non-normal!)\n",
    "population = (4 * np.random.randn(popN)) ** 2\n",
    "\n",
    "# we can calculate the exact population mean\n",
    "popMean = np.mean(population)\n",
    "\n",
    "# let's see it\n",
    "fig, ax = plt.subplots(2, 1, figsize = (13, 8))\n",
    "\n",
    "# only plot every 1000th sample\n",
    "ax[0].plot(population[::1000], 'k.')\n",
    "ax[0].set_xlabel('Data index')\n",
    "ax[0].set_ylabel('Data value')\n",
    "\n",
    "ax[1].hist(population, bins = 'fd') #Freedman Diaconis Estimator\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[1].set_xlabel('Data value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw a random sample\n",
    "\n",
    "# parameters\n",
    "samplesize = 40\n",
    "confidence = 0.95\n",
    "\n",
    "# compute sample mean\n",
    "sample  = np.random.choice(population, samplesize)\n",
    "samplemean  = np.mean(sample)\n",
    "samplestd   = np.std(sample) # used later for analytic solution\n",
    "\n",
    "\n",
    "\n",
    "### now for bootstrapping\n",
    "numBoots  = 1000\n",
    "bootmeans = np.zeros(numBoots)\n",
    "\n",
    "# resample with replacement\n",
    "for i in range(numBoots):\n",
    "    bootmeans[i] = np.mean(np.random.choice(sample, samplesize))\n",
    "    \n",
    "\n",
    "# find confidence intervals\n",
    "confint = [0, 0] # initialize\n",
    "confint[0] = np.percentile(bootmeans, (100 - (confidence * 100)) / 2)\n",
    "confint[1] = np.percentile(bootmeans, 100 - (100 - (confidence * 100)) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice([1, 2, 3, 4, 5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## graph everything\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "# start with histogram of resampled means\n",
    "ax.hist(bootmeans, bins = 'fd', label = 'Empirical dist.')\n",
    "\n",
    "y = np.array([[confint[0], 0], [confint[1], 0], [confint[1], 120], [confint[0], 120]])\n",
    "p = Polygon(y, facecolor = 'g', alpha = 0.3, label = '{}% CI region'.format(confidence * 100))\n",
    "ax.add_patch(p)\n",
    "\n",
    "# now add the lines\n",
    "ax.axvline(popMean, color = 'k', linewidth = 2, linestyle = ':', label = 'True mean')\n",
    "ax.axvline(samplemean, color = 'r', linestyle = '--', linewidth = 3, alpha = 0.7, label = 'Sample mean')\n",
    "ax.set_xlim([popMean-30, popMean+30])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Data values')\n",
    "ax.legend(prop = {'size' : 15});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare against the analytic confidence interval\n",
    "\n",
    "# compute confidence intervals\n",
    "citmp = (1 - confidence) / 2\n",
    "confint2 = samplemean + stats.t.ppf([citmp, 1 - citmp], samplesize - 1) * samplestd / np.sqrt(samplesize)\n",
    "\n",
    "print('Empirical: [{}, {}]'.format(np.round(confint[0], 2), np.round(confint[1], 2)))\n",
    "print('Analytic:  [{}, {}]'.format(np.round(confint2[0], 2), np.round(confint2[1], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "El siguiente DataFrame contiene información sobre una encuesta en la que la gente califica su felicidad en un puntaje del 1 al 10 en diferentes países.\n",
    "\n",
    "- Con los datos proporcionados a continuación, ¿Se puede afirmar que hay una diferencia entre lo felices que son las personas en Europa Oriental y Latinoamérica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al contenido](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
